# Mojo Embedding Service - Production Deployment Guide

**Version:** 1.0  
**Date:** 2026-01-11  
**Status:** Production Ready  

---

## ðŸŽ¯ Quick Start

### Local Development
```bash
# Start service directly
python3 src/serviceCore/serviceEmbedding-mojo/server.py

# Service available at http://localhost:8007
# API Docs: http://localhost:8007/docs
```

### Docker Deployment
```bash
# Build image
docker build -f docker/Dockerfile.mojo-embedding -t mojo-embedding:latest .

# Run container
docker run -d -p 8007:8007 --name mojo-embedding mojo-embedding:latest

# Check health
curl http://localhost:8007/health
```

### Docker Compose
```bash
# Start service
docker-compose -f docker/compose/docker-compose.mojo-embedding.yml up -d

# View logs
docker-compose -f docker/compose/docker-compose.mojo-embedding.yml logs -f

# Stop service
docker-compose -f docker/compose/docker-compose.mojo-embedding.yml down
```

---

## ðŸ“‹ System Requirements

### Minimum Requirements
- **CPU:** 2 cores
- **RAM:** 2GB
- **Disk:** 1GB (for models)
- **OS:** Linux, macOS, Windows

### Recommended for Production
- **CPU:** 4+ cores
- **RAM:** 4GB+
- **Disk:** 2GB SSD
- **GPU:** Optional (NVIDIA CUDA for 5-10x speedup)

### With GPU (Optional)
- **CUDA:** 11.8+
- **GPU Memory:** 2GB+
- **Performance:** 5-10x faster inference

---

## ðŸš€ Deployment Options

### Option 1: Direct Python (Development)

**Pros:**
- Fast iteration
- Easy debugging
- No containerization overhead

**Cons:**
- Manual dependency management
- Not portable

**Steps:**
```bash
# 1. Install dependencies
pip install sentence-transformers torch fastapi uvicorn

# 2. Run service
cd /path/to/project
python3 src/serviceCore/serviceEmbedding-mojo/server.py

# 3. Test
curl http://localhost:8007/health
```

### Option 2: Docker (Recommended)

**Pros:**
- Portable
- Consistent environment
- Easy scaling
- Resource limits

**Cons:**
- Slightly more overhead
- Requires Docker

**Steps:**
```bash
# 1. Build image
docker build -f docker/Dockerfile.mojo-embedding -t mojo-embedding:latest .

# 2. Run with resource limits
docker run -d \
  --name mojo-embedding \
  -p 8007:8007 \
  --cpus="2.0" \
  --memory="4g" \
  --restart=unless-stopped \
  mojo-embedding:latest

# 3. Monitor
docker logs -f mojo-embedding
docker stats mojo-embedding
```

### Option 3: Docker Compose (Production)

**Pros:**
- Easy orchestration
- Service dependencies
- Volume management
- Network isolation

**Cons:**
- More complex setup

**Steps:**
```bash
# 1. Create network (if needed)
docker network create app-network

# 2. Start service
docker-compose -f docker/compose/docker-compose.mojo-embedding.yml up -d

# 3. Scale (if needed)
docker-compose -f docker/compose/docker-compose.mojo-embedding.yml up -d --scale mojo-embedding=3

# 4. Update
docker-compose -f docker/compose/docker-compose.mojo-embedding.yml pull
docker-compose -f docker/compose/docker-compose.mojo-embedding.yml up -d
```

### Option 4: Kubernetes (Enterprise)

**Deployment YAML:**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mojo-embedding
spec:
  replicas: 3
  selector:
    matchLabels:
      app: mojo-embedding
  template:
    metadata:
      labels:
        app: mojo-embedding
    spec:
      containers:
      - name: mojo-embedding
        image: mojo-embedding:latest
        ports:
        - containerPort: 8007
        resources:
          limits:
            cpu: "2"
            memory: "4Gi"
          requests:
            cpu: "1"
            memory: "2Gi"
        livenessProbe:
          httpGet:
            path: /health
            port: 8007
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /health
            port: 8007
          initialDelaySeconds: 30
          periodSeconds: 10
---
apiVersion: v1
kind: Service
metadata:
  name: mojo-embedding-service
spec:
  selector:
    app: mojo-embedding
  ports:
  - port: 8007
    targetPort: 8007
  type: LoadBalancer
```

---

## ðŸ”§ Configuration

### Environment Variables

```bash
# Logging
export LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR

# Python
export PYTHONUNBUFFERED=1

# Model cache (optional)
export TRANSFORMERS_CACHE=/path/to/cache

# GPU (if available)
export CUDA_VISIBLE_DEVICES=0
```

### Resource Limits

#### CPU-Only Deployment
```yaml
resources:
  limits:
    cpus: '2.0'
    memory: 4G
  reservations:
    cpus: '1.0'
    memory: 2G
```

#### GPU Deployment
```yaml
resources:
  limits:
    cpus: '4.0'
    memory: 8G
  reservations:
    cpus: '2.0'
    memory: 4G
deploy:
  resources:
    reservations:
      devices:
      - driver: nvidia
        count: 1
        capabilities: [gpu]
```

---

## ðŸ“Š Monitoring & Health Checks

### Health Endpoint
```bash
curl http://localhost:8007/health

# Response
{
  "status": "healthy",
  "service": "embedding-mojo",
  "version": "0.1.0",
  "models": {...},
  "timestamp": "2026-01-11T..."
}
```

### Metrics Endpoint
```bash
curl http://localhost:8007/metrics

# Response
{
  "requests_total": 100,
  "requests_per_second": 2.5,
  "average_latency_ms": 72.5,
  "cache_hit_rate": 0.15,
  "embeddings_generated": 250,
  "uptime_seconds": 3600,
  "device": "cpu"
}
```

### Monitoring Integration

#### Prometheus
```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'mojo-embedding'
    static_configs:
      - targets: ['localhost:8007']
    metrics_path: '/metrics'
    scrape_interval: 15s
```

#### Grafana Dashboard
```json
{
  "dashboard": {
    "title": "Mojo Embedding Service",
    "panels": [
      {
        "title": "Request Rate",
        "targets": [{"expr": "rate(requests_total[5m])"}]
      },
      {
        "title": "Latency",
        "targets": [{"expr": "average_latency_ms"}]
      },
      {
        "title": "Cache Hit Rate",
        "targets": [{"expr": "cache_hit_rate"}]
      }
    ]
  }
}
```

---

## ðŸ”¥ Performance Tuning

### Optimization Checklist

- [ ] Use GPU if available (5-10x speedup)
- [ ] Enable FP16 on GPU (2x speedup)
- [ ] Increase batch size for throughput
- [ ] Monitor cache hit rate
- [ ] Scale horizontally for load
- [ ] Use load balancer
- [ ] Enable keep-alive connections
- [ ] Optimize model selection

### Load Balancing (NGINX)

```nginx
upstream mojo_embedding {
    least_conn;
    server localhost:8007;
    server localhost:8008;
    server localhost:8009;
}

server {
    listen 80;
    location / {
        proxy_pass http://mojo_embedding;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

### Horizontal Scaling

```bash
# Docker Compose
docker-compose up -d --scale mojo-embedding=3

# Kubernetes
kubectl scale deployment mojo-embedding --replicas=5
```

---

## ðŸ›¡ï¸ Security

### Best Practices

1. **API Authentication** (Add in production)
```python
from fastapi.security import HTTPBearer

security = HTTPBearer()

@app.post("/embed/single")
async def embed_single(request: EmbedSingleRequest, token: str = Depends(security)):
    # Verify token
    ...
```

2. **Rate Limiting**
```python
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter

@app.post("/embed/single")
@limiter.limit("100/minute")
async def embed_single(request: Request, ...):
    ...
```

3. **HTTPS/TLS**
```bash
# Use reverse proxy (NGINX, Caddy)
server {
    listen 443 ssl;
    ssl_certificate /path/to/cert.pem;
    ssl_certificate_key /path/to/key.pem;
    location / {
        proxy_pass http://localhost:8007;
    }
}
```

---

## ðŸ§ª Testing

### Smoke Test
```bash
#!/bin/bash
# test_deployment.sh

echo "Testing Mojo Embedding Service..."

# Health check
curl -f http://localhost:8007/health || exit 1

# Single embedding
curl -X POST http://localhost:8007/embed/single \
  -H "Content-Type: application/json" \
  -d '{"text":"test"}' || exit 1

# Batch embedding
curl -X POST http://localhost:8007/embed/batch \
  -H "Content-Type: application/json" \
  -d '{"texts":["test1","test2"]}' || exit 1

echo "âœ“ All tests passed!"
```

### Load Test
```bash
# Using hey
hey -n 1000 -c 10 -m POST \
  -H "Content-Type: application/json" \
  -d '{"text":"test"}' \
  http://localhost:8007/embed/single
```

---

## ðŸ“ Maintenance

### Backup
```bash
# Backup cache
tar -czf embedding-cache-backup.tar.gz ~/.cache/torch/

# Backup logs
tar -czf logs-backup.tar.gz ./logs/
```

### Updates
```bash
# Pull latest code
git pull origin main

# Rebuild image
docker build -f docker/Dockerfile.mojo-embedding -t mojo-embedding:latest .

# Rolling update
docker-compose up -d --no-deps --build mojo-embedding
```

### Troubleshooting

**Service won't start:**
```bash
# Check logs
docker logs mojo-embedding

# Check resources
docker stats mojo-embedding

# Verify network
docker network inspect app-network
```

**Slow performance:**
```bash
# Check metrics
curl http://localhost:8007/metrics

# Monitor resource usage
docker stats

# Check cache hit rate
# If low, may need more memory
```

**High memory usage:**
```bash
# Reduce cache size in code
self.embedding_cache = {}  # Limit: 10000 -> 5000

# Restart service
docker-compose restart mojo-embedding
```

---

## ðŸ“Š Performance Benchmarks

### Current Performance (CPU)
- **Latency:** 72ms for 3 texts
- **Throughput:** ~40 texts/second
- **Memory:** ~2-3GB
- **CPU:** 2 cores

### With GPU (Projected)
- **Latency:** 10-20ms for 3 texts
- **Throughput:** 150-300 texts/second
- **Memory:** ~4-6GB (GPU)
- **Speedup:** 5-10x

### Future (Mojo + SIMD)
- **Latency:** <1ms per text
- **Throughput:** 3000+ texts/second
- **Speedup:** 10-15x over current

---

## âœ… Production Checklist

- [ ] Docker image built and tested
- [ ] Health checks configured
- [ ] Resource limits set
- [ ] Monitoring configured
- [ ] Logging configured
- [ ] Backup strategy defined
- [ ] Load balancer configured (if needed)
- [ ] Security measures in place
- [ ] Documentation complete
- [ ] Team trained

---

## ðŸ“ž Support

**Documentation:** `docs/implementation/`  
**API Docs:** http://localhost:8007/docs  
**Health:** http://localhost:8007/health  
**Metrics:** http://localhost:8007/metrics  

---

**Version:** 1.0  
**Last Updated:** 2026-01-11  
**Status:** Production Ready âœ…
