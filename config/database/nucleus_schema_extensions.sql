-- ============================================================================
-- NUCLEUS SCHEMA EXTENSIONS - Days 1-3 Features
-- ============================================================================
-- Created: 2026-01-21
-- Purpose: Extend existing HANA schema with tables for Model Configurator,
--          Settings, Notifications, and T-Account Comparisons
-- Dependencies: prompt_modes_schema.sql (must be executed first)
-- ============================================================================

-- ============================================================================
-- PRIORITY 1: MODEL CONFIGURATIONS (Day 1 Feature)
-- ============================================================================

DROP TABLE IF EXISTS MODEL_CONFIGURATIONS;

CREATE COLUMN TABLE MODEL_CONFIGURATIONS (
    CONFIG_ID VARCHAR(36) PRIMARY KEY,
    MODEL_ID VARCHAR(100) NOT NULL,
    USER_ID VARCHAR(100),
    
    -- Inference Parameters (from Day 1 Model Configurator Dialog)
    TEMPERATURE DECIMAL(3,2) DEFAULT 0.7 
        CHECK (TEMPERATURE >= 0.0 AND TEMPERATURE <= 2.0),
    TOP_P DECIMAL(3,2) DEFAULT 0.9 
        CHECK (TOP_P >= 0.0 AND TOP_P <= 1.0),
    TOP_K INTEGER DEFAULT 40 
        CHECK (TOP_K >= 0 AND TOP_K <= 100),
    MAX_TOKENS INTEGER DEFAULT 2048 
        CHECK (MAX_TOKENS > 0),
    CONTEXT_LENGTH INTEGER DEFAULT 4096 
        CHECK (CONTEXT_LENGTH > 0),
    REPEAT_PENALTY DECIMAL(3,2) DEFAULT 1.1 
        CHECK (REPEAT_PENALTY >= 0.5 AND REPEAT_PENALTY <= 2.0),
    PRESENCE_PENALTY DECIMAL(4,2) DEFAULT 0.0 
        CHECK (PRESENCE_PENALTY >= -2.0 AND PRESENCE_PENALTY <= 2.0),
    FREQUENCY_PENALTY DECIMAL(4,2) DEFAULT 0.0 
        CHECK (FREQUENCY_PENALTY >= -2.0 AND FREQUENCY_PENALTY <= 2.0),
    
    -- Advanced Options
    ENABLE_STREAMING BOOLEAN DEFAULT TRUE,
    ENABLE_CACHE BOOLEAN DEFAULT TRUE,
    LOG_PROBS BOOLEAN DEFAULT FALSE,
    SEED INTEGER,
    STOP_SEQUENCES VARCHAR(500),
    
    -- Metadata
    IS_DEFAULT BOOLEAN DEFAULT FALSE,
    CONFIG_NAME VARCHAR(200),
    DESCRIPTION VARCHAR(500),
    CREATED_AT TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UPDATED_AT TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    CONSTRAINT UQ_USER_MODEL_DEFAULT UNIQUE (USER_ID, MODEL_ID, IS_DEFAULT)
);

CREATE INDEX IDX_MC_MODEL ON MODEL_CONFIGURATIONS(MODEL_ID);
CREATE INDEX IDX_MC_USER ON MODEL_CONFIGURATIONS(USER_ID);
CREATE INDEX IDX_MC_DEFAULT ON MODEL_CONFIGURATIONS(IS_DEFAULT);

COMMENT ON TABLE MODEL_CONFIGURATIONS IS 'Stores per-model inference configurations from Model Configurator dialog';

-- ============================================================================
-- PRIORITY 2: USER SETTINGS (Day 2 Feature)
-- ============================================================================

DROP TABLE IF EXISTS USER_SETTINGS;

CREATE COLUMN TABLE USER_SETTINGS (
    USER_ID VARCHAR(100) PRIMARY KEY,
    
    -- General Settings (4 fields)
    THEME VARCHAR(50) DEFAULT 'sap_horizon',
    LANGUAGE VARCHAR(10) DEFAULT 'en',
    DATE_FORMAT VARCHAR(20) DEFAULT 'MM/DD/YYYY',
    TIME_FORMAT VARCHAR(10) DEFAULT '12h',
    
    -- API Configuration (5 fields)
    API_BASE_URL VARCHAR(500) DEFAULT 'http://localhost:8080',
    WEBSOCKET_URL VARCHAR(500) DEFAULT 'ws://localhost:8080/ws',
    API_KEY_ENCRYPTED VARCHAR(500),
    REQUEST_TIMEOUT_SEC INTEGER DEFAULT 30 
        CHECK (REQUEST_TIMEOUT_SEC >= 5 AND REQUEST_TIMEOUT_SEC <= 120),
    ENABLE_API_CACHE BOOLEAN DEFAULT TRUE,
    
    -- Dashboard Settings (6 fields)
    AUTO_REFRESH BOOLEAN DEFAULT TRUE,
    REFRESH_INTERVAL_SEC INTEGER DEFAULT 10 
        CHECK (REFRESH_INTERVAL_SEC >= 5 AND REFRESH_INTERVAL_SEC <= 60),
    SHOW_ADVANCED_METRICS BOOLEAN DEFAULT FALSE,
    ENABLE_CHART_ANIMATION BOOLEAN DEFAULT TRUE,
    COMPACT_MODE BOOLEAN DEFAULT FALSE,
    DEFAULT_CHART_RANGE VARCHAR(10) DEFAULT '1h',
    
    -- Notification Settings (4 fields + JSON)
    ENABLE_DESKTOP_NOTIFICATIONS BOOLEAN DEFAULT FALSE,
    ENABLE_NOTIFICATION_SOUND BOOLEAN DEFAULT FALSE,
    NOTIFICATION_TYPES_JSON NCLOB,  -- {system: true, model: true, training: true, performance: true}
    AUTO_DISMISS_TIMEOUT_SEC INTEGER DEFAULT 10 
        CHECK (AUTO_DISMISS_TIMEOUT_SEC >= 0 AND AUTO_DISMISS_TIMEOUT_SEC <= 60),
    
    -- Privacy Settings (3 fields)
    SAVE_PROMPT_HISTORY BOOLEAN DEFAULT TRUE,
    ENABLE_ANALYTICS BOOLEAN DEFAULT FALSE,
    ENABLE_ERROR_REPORTING BOOLEAN DEFAULT TRUE,
    
    -- Metadata
    CREATED_AT TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UPDATED_AT TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

COMMENT ON TABLE USER_SETTINGS IS 'Stores per-user application settings from Settings dialog (25+ configurable options)';

-- ============================================================================
-- PRIORITY 3: NOTIFICATIONS (Day 2 Feature)
-- ============================================================================

DROP TABLE IF EXISTS NOTIFICATIONS;

CREATE COLUMN TABLE NOTIFICATIONS (
    NOTIFICATION_ID VARCHAR(36) PRIMARY KEY,
    USER_ID VARCHAR(100),
    
    -- Notification Details
    TYPE VARCHAR(20) NOT NULL CHECK (TYPE IN ('error', 'warning', 'info')),
    CATEGORY VARCHAR(50) NOT NULL,
    TITLE VARCHAR(200) NOT NULL,
    MESSAGE VARCHAR(1000),
    
    -- Action
    ACTION VARCHAR(100),
    ACTION_TEXT VARCHAR(100),
    ACTION_URL VARCHAR(500),
    
    -- Status Tracking
    IS_READ BOOLEAN DEFAULT FALSE,
    READ_AT TIMESTAMP,
    IS_DISMISSED BOOLEAN DEFAULT FALSE,
    DISMISSED_AT TIMESTAMP,
    
    -- Priority and Visibility
    PRIORITY INTEGER DEFAULT 1 CHECK (PRIORITY BETWEEN 1 AND 5),
    IS_STICKY BOOLEAN DEFAULT FALSE,  -- Sticky notifications don't auto-dismiss
    
    -- Metadata
    CREATED_AT TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    EXPIRES_AT TIMESTAMP,
    SOURCE_SYSTEM VARCHAR(100),  -- Which component generated this
    CORRELATION_ID VARCHAR(36)   -- Link to related entity
);

CREATE INDEX IDX_NOTIF_USER ON NOTIFICATIONS(USER_ID);
CREATE INDEX IDX_NOTIF_TYPE ON NOTIFICATIONS(TYPE);
CREATE INDEX IDX_NOTIF_CATEGORY ON NOTIFICATIONS(CATEGORY);
CREATE INDEX IDX_NOTIF_READ ON NOTIFICATIONS(IS_READ);
CREATE INDEX IDX_NOTIF_CREATED ON NOTIFICATIONS(CREATED_AT);
CREATE INDEX IDX_NOTIF_EXPIRES ON NOTIFICATIONS(EXPIRES_AT);

COMMENT ON TABLE NOTIFICATIONS IS 'System notifications for Notifications Popover (error/warning/info types)';

-- ============================================================================
-- PRIORITY 4: PROMPT COMPARISONS (Day 3 Feature - T-Account)
-- ============================================================================

DROP TABLE IF EXISTS PROMPT_COMPARISONS;

CREATE COLUMN TABLE PROMPT_COMPARISONS (
    COMPARISON_ID VARCHAR(36) PRIMARY KEY,
    USER_ID VARCHAR(100),
    COMPARISON_NAME VARCHAR(200),
    
    -- Prompt A Details
    PROMPT_A_ID VARCHAR(36),
    PROMPT_A_TEXT NCLOB,
    PROMPT_A_MODE VARCHAR(50),
    PROMPT_A_MODEL VARCHAR(100),
    PROMPT_A_STATUS VARCHAR(20) DEFAULT 'Success',
    PROMPT_A_RESPONSE NCLOB,
    
    -- Prompt A Metrics
    PROMPT_A_LATENCY_MS INTEGER,
    PROMPT_A_TTFT_MS INTEGER,
    PROMPT_A_TPS DECIMAL(10,2),
    PROMPT_A_TOKEN_COUNT INTEGER,
    PROMPT_A_COST_ESTIMATE DECIMAL(10,6),
    
    -- Prompt B Details
    PROMPT_B_ID VARCHAR(36),
    PROMPT_B_TEXT NCLOB,
    PROMPT_B_MODE VARCHAR(50),
    PROMPT_B_MODEL VARCHAR(100),
    PROMPT_B_STATUS VARCHAR(20) DEFAULT 'Success',
    PROMPT_B_RESPONSE NCLOB,
    
    -- Prompt B Metrics
    PROMPT_B_LATENCY_MS INTEGER,
    PROMPT_B_TTFT_MS INTEGER,
    PROMPT_B_TPS DECIMAL(10,2),
    PROMPT_B_TOKEN_COUNT INTEGER,
    PROMPT_B_COST_ESTIMATE DECIMAL(10,6),
    
    -- Winner Determination
    OVERALL_WINNER VARCHAR(1) CHECK (OVERALL_WINNER IN ('A', 'B', NULL)),
    LATENCY_WINNER VARCHAR(1) CHECK (LATENCY_WINNER IN ('A', 'B', NULL)),
    TTFT_WINNER VARCHAR(1) CHECK (TTFT_WINNER IN ('A', 'B', NULL)),
    TPS_WINNER VARCHAR(1) CHECK (TPS_WINNER IN ('A', 'B', NULL)),
    COST_WINNER VARCHAR(1) CHECK (COST_WINNER IN ('A', 'B', NULL)),
    
    -- Analysis
    NOTES VARCHAR(1000),
    WINNER_RATIONALE VARCHAR(500),
    
    -- Metadata
    IS_SAVED BOOLEAN DEFAULT FALSE,
    IS_FAVORITE BOOLEAN DEFAULT FALSE,
    TAGS VARCHAR(500),  -- Comma-separated tags
    CREATED_AT TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UPDATED_AT TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX IDX_PC_USER ON PROMPT_COMPARISONS(USER_ID);
CREATE INDEX IDX_PC_CREATED ON PROMPT_COMPARISONS(CREATED_AT);
CREATE INDEX IDX_PC_WINNER ON PROMPT_COMPARISONS(OVERALL_WINNER);
CREATE INDEX IDX_PC_SAVED ON PROMPT_COMPARISONS(IS_SAVED);

COMMENT ON TABLE PROMPT_COMPARISONS IS 'T-Account Prompt Comparison data (A vs B side-by-side)';

-- ============================================================================
-- PRIORITY 4: MODEL VERSION COMPARISONS (Day 3 Feature - T-Account)
-- ============================================================================

DROP TABLE IF EXISTS MODEL_VERSIONS;
DROP TABLE IF EXISTS MODEL_VERSION_COMPARISONS;

-- First create MODEL_VERSIONS table (supporting table)
CREATE COLUMN TABLE MODEL_VERSIONS (
    VERSION_ID VARCHAR(36) PRIMARY KEY,
    MODEL_NAME VARCHAR(100) NOT NULL,
    VERSION_NUMBER VARCHAR(50) NOT NULL,
    
    -- Status
    STATUS VARCHAR(20) DEFAULT 'DRAFT' 
        CHECK (STATUS IN ('DRAFT', 'STAGING', 'PRODUCTION', 'ARCHIVED')),
    
    -- Training Reference
    TRAINING_EXPERIMENT_ID VARCHAR(36),
    BASE_MODEL_ID VARCHAR(100),
    
    -- Metadata
    CREATED_DATE TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    PROMOTED_DATE TIMESTAMP,
    PROMOTED_BY VARCHAR(100),
    ARCHIVED_DATE TIMESTAMP,
    
    -- Metrics Snapshot (JSON)
    TRAINING_METRICS_JSON NCLOB,
    INFERENCE_METRICS_JSON NCLOB,
    AB_TESTING_STATS_JSON NCLOB,
    
    -- Notes
    DESCRIPTION VARCHAR(1000),
    CHANGELOG NCLOB,
    
    CONSTRAINT UQ_MODEL_VERSION UNIQUE (MODEL_NAME, VERSION_NUMBER)
);

CREATE INDEX IDX_MV_MODEL ON MODEL_VERSIONS(MODEL_NAME);
CREATE INDEX IDX_MV_STATUS ON MODEL_VERSIONS(STATUS);
CREATE INDEX IDX_MV_CREATED ON MODEL_VERSIONS(CREATED_DATE);

-- Now create comparisons table
CREATE COLUMN TABLE MODEL_VERSION_COMPARISONS (
    COMPARISON_ID VARCHAR(36) PRIMARY KEY,
    MODEL_NAME VARCHAR(100) NOT NULL,
    
    -- Version A Reference
    VERSION_A_ID VARCHAR(36) NOT NULL,
    VERSION_A_NAME VARCHAR(50),
    VERSION_A_STATUS VARCHAR(20),
    VERSION_A_CREATED_DATE TIMESTAMP,
    VERSION_A_PROMOTED_BY VARCHAR(100),
    VERSION_A_TRAINING_EXP_ID VARCHAR(36),
    
    -- Version A Metrics (detailed JSON storage)
    VERSION_A_TRAINING_METRICS_JSON NCLOB,
    VERSION_A_INFERENCE_METRICS_JSON NCLOB,
    VERSION_A_AB_TESTING_JSON NCLOB,
    
    -- Version B Reference
    VERSION_B_ID VARCHAR(36) NOT NULL,
    VERSION_B_NAME VARCHAR(50),
    VERSION_B_STATUS VARCHAR(20),
    VERSION_B_CREATED_DATE TIMESTAMP,
    VERSION_B_PROMOTED_BY VARCHAR(100),
    VERSION_B_TRAINING_EXP_ID VARCHAR(36),
    
    -- Version B Metrics (detailed JSON storage)
    VERSION_B_TRAINING_METRICS_JSON NCLOB,
    VERSION_B_INFERENCE_METRICS_JSON NCLOB,
    VERSION_B_AB_TESTING_JSON NCLOB,
    
    -- Delta Analysis
    DELTAS_JSON NCLOB,  -- All delta calculations
    OVERALL_WINNER VARCHAR(1) CHECK (OVERALL_WINNER IN ('A', 'B', NULL)),
    RECOMMENDATION VARCHAR(1000),
    
    -- Summary Statistics
    METRICS_WON_BY_A INTEGER DEFAULT 0,
    METRICS_WON_BY_B INTEGER DEFAULT 0,
    METRICS_TIED INTEGER DEFAULT 0,
    
    -- Metadata
    CREATED_BY VARCHAR(100),
    CREATED_AT TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    COMPARISON_NOTES NCLOB,
    
    -- Foreign Keys
    CONSTRAINT FK_VERSION_A FOREIGN KEY (VERSION_A_ID) 
        REFERENCES MODEL_VERSIONS(VERSION_ID) ON DELETE CASCADE,
    CONSTRAINT FK_VERSION_B FOREIGN KEY (VERSION_B_ID) 
        REFERENCES MODEL_VERSIONS(VERSION_ID) ON DELETE CASCADE
);

CREATE INDEX IDX_MVC_MODEL ON MODEL_VERSION_COMPARISONS(MODEL_NAME);
CREATE INDEX IDX_MVC_VERSION_A ON MODEL_VERSION_COMPARISONS(VERSION_A_ID);
CREATE INDEX IDX_MVC_VERSION_B ON MODEL_VERSION_COMPARISONS(VERSION_B_ID);
CREATE INDEX IDX_MVC_WINNER ON MODEL_VERSION_COMPARISONS(OVERALL_WINNER);
CREATE INDEX IDX_MVC_CREATED ON MODEL_VERSION_COMPARISONS(CREATED_AT);

COMMENT ON TABLE MODEL_VERSIONS IS 'Version history for ML models with status tracking';
COMMENT ON TABLE MODEL_VERSION_COMPARISONS IS 'T-Account Model Version Comparison data (Version A vs B)';

-- ============================================================================
-- PRIORITY 4: TRAINING EXPERIMENT COMPARISONS (Day 3 Feature - T-Account)
-- ============================================================================

DROP TABLE IF EXISTS TRAINING_EXPERIMENTS;
DROP TABLE IF EXISTS TRAINING_EXPERIMENT_COMPARISONS;

-- First create TRAINING_EXPERIMENTS table (supporting table)
CREATE COLUMN TABLE TRAINING_EXPERIMENTS (
    EXPERIMENT_ID VARCHAR(36) PRIMARY KEY,
    EXPERIMENT_NAME VARCHAR(200) NOT NULL,
    
    -- Status
    STATUS VARCHAR(20) DEFAULT 'PENDING' 
        CHECK (STATUS IN ('PENDING', 'RUNNING', 'COMPLETED', 'FAILED', 'CANCELLED')),
    
    -- Model Configuration
    BASE_MODEL VARCHAR(100) NOT NULL,
    FINE_TUNING_METHOD VARCHAR(20) DEFAULT 'LoRA' 
        CHECK (FINE_TUNING_METHOD IN ('LoRA', 'mHC', 'Full', 'QLoRA')),
    
    -- Training Parameters (JSON for flexibility)
    TRAINING_PARAMS_JSON NCLOB,
    
    -- Specific Parameters (for querying)
    LEARNING_RATE DECIMAL(10,8),
    BATCH_SIZE INTEGER,
    EPOCHS INTEGER,
    OPTIMIZER VARCHAR(50),
    WARMUP_STEPS INTEGER,
    
    -- Timing
    START_TIME TIMESTAMP,
    END_TIME TIMESTAMP,
    DURATION_SECONDS INTEGER,
    
    -- Training Metrics
    INITIAL_LOSS DECIMAL(10,6),
    FINAL_LOSS DECIMAL(10,6),
    INITIAL_ACCURACY DECIMAL(5,2),
    FINAL_ACCURACY DECIMAL(5,2),
    SAMPLES_PROCESSED INTEGER,
    
    -- Resource Usage
    PEAK_GPU_MEMORY_GB DECIMAL(10,2),
    AVG_GPU_UTILIZATION_PERCENT DECIMAL(5,2),
    TOTAL_TOKENS_PROCESSED BIGINT,
    
    -- Results
    OUTPUT_MODEL_PATH VARCHAR(500),
    CHECKPOINT_PATH VARCHAR(500),
    LOGS_PATH VARCHAR(500),
    
    -- Metadata
    CREATED_BY VARCHAR(100),
    CREATED_AT TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UPDATED_AT TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    NOTES NCLOB
);

CREATE INDEX IDX_TE_STATUS ON TRAINING_EXPERIMENTS(STATUS);
CREATE INDEX IDX_TE_BASE_MODEL ON TRAINING_EXPERIMENTS(BASE_MODEL);
CREATE INDEX IDX_TE_METHOD ON TRAINING_EXPERIMENTS(FINE_TUNING_METHOD);
CREATE INDEX IDX_TE_CREATED ON TRAINING_EXPERIMENTS(CREATED_AT);
CREATE INDEX IDX_TE_CREATOR ON TRAINING_EXPERIMENTS(CREATED_BY);

-- Now create comparisons table
CREATE COLUMN TABLE TRAINING_EXPERIMENT_COMPARISONS (
    COMPARISON_ID VARCHAR(36) PRIMARY KEY,
    COMPARISON_NAME VARCHAR(200),
    
    -- Experiment A Reference
    EXPERIMENT_A_ID VARCHAR(36) NOT NULL,
    EXPERIMENT_A_NAME VARCHAR(200),
    EXPERIMENT_A_STATUS VARCHAR(20),
    EXPERIMENT_A_BASE_MODEL VARCHAR(100),
    EXPERIMENT_A_METHOD VARCHAR(20),
    
    -- Experiment A Data (JSON for full detail)
    EXPERIMENT_A_PARAMS_JSON NCLOB,
    EXPERIMENT_A_METRICS_JSON NCLOB,
    EXPERIMENT_A_RESOURCES_JSON NCLOB,
    
    -- Experiment B Reference
    EXPERIMENT_B_ID VARCHAR(36) NOT NULL,
    EXPERIMENT_B_NAME VARCHAR(200),
    EXPERIMENT_B_STATUS VARCHAR(20),
    EXPERIMENT_B_BASE_MODEL VARCHAR(100),
    EXPERIMENT_B_METHOD VARCHAR(20),
    
    -- Experiment B Data (JSON for full detail)
    EXPERIMENT_B_PARAMS_JSON NCLOB,
    EXPERIMENT_B_METRICS_JSON NCLOB,
    EXPERIMENT_B_RESOURCES_JSON NCLOB,
    
    -- Analysis Results
    ANALYSIS_JSON NCLOB,  -- All delta calculations
    
    -- Winners
    OVERALL_WINNER VARCHAR(1) CHECK (OVERALL_WINNER IN ('A', 'B', NULL)),
    CONVERGENCE_WINNER VARCHAR(1) CHECK (CONVERGENCE_WINNER IN ('A', 'B', NULL)),
    LOSS_WINNER VARCHAR(1) CHECK (LOSS_WINNER IN ('A', 'B', NULL)),
    ACCURACY_WINNER VARCHAR(1) CHECK (ACCURACY_WINNER IN ('A', 'B', NULL)),
    EFFICIENCY_WINNER VARCHAR(1) CHECK (EFFICIENCY_WINNER IN ('A', 'B', NULL)),
    
    -- Deltas (for quick querying)
    CONVERGENCE_DELTA_PERCENT DECIMAL(6,2),
    LOSS_DELTA_PERCENT DECIMAL(6,2),
    ACCURACY_DELTA_PERCENT DECIMAL(6,2),
    EFFICIENCY_DELTA_PERCENT DECIMAL(6,2),
    
    -- Recommendation
    RECOMMENDATION VARCHAR(1000),
    OVERALL_SCORE VARCHAR(100),  -- e.g., "85/100 vs 78/100"
    
    -- Metadata
    CREATED_BY VARCHAR(100),
    CREATED_AT TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    NOTES NCLOB,
    
    -- Foreign Keys
    CONSTRAINT FK_EXPERIMENT_A FOREIGN KEY (EXPERIMENT_A_ID) 
        REFERENCES TRAINING_EXPERIMENTS(EXPERIMENT_ID) ON DELETE CASCADE,
    CONSTRAINT FK_EXPERIMENT_B FOREIGN KEY (EXPERIMENT_B_ID) 
        REFERENCES TRAINING_EXPERIMENTS(EXPERIMENT_ID) ON DELETE CASCADE
);

CREATE INDEX IDX_TEC_EXP_A ON TRAINING_EXPERIMENT_COMPARISONS(EXPERIMENT_A_ID);
CREATE INDEX IDX_TEC_EXP_B ON TRAINING_EXPERIMENT_COMPARISONS(EXPERIMENT_B_ID);
CREATE INDEX IDX_TEC_WINNER ON TRAINING_EXPERIMENT_COMPARISONS(OVERALL_WINNER);
CREATE INDEX IDX_TEC_CREATED ON TRAINING_EXPERIMENT_COMPARISONS(CREATED_AT);
CREATE INDEX IDX_TEC_CREATOR ON TRAINING_EXPERIMENT_COMPARISONS(CREATED_BY);

COMMENT ON TABLE TRAINING_EXPERIMENTS IS 'Training job metadata and metrics';
COMMENT ON TABLE TRAINING_EXPERIMENT_COMPARISONS IS 'T-Account Training Experiment Comparison data (Experiment A vs B)';

-- ============================================================================
-- SUPPORTING TABLE: AUDIT LOG (Security & Compliance)
-- ============================================================================

DROP TABLE IF EXISTS AUDIT_LOG;

CREATE COLUMN TABLE AUDIT_LOG (
    AUDIT_ID VARCHAR(36) PRIMARY KEY,
    
    -- Who, What, When
    USER_ID VARCHAR(100) NOT NULL,
    ACTION VARCHAR(100) NOT NULL,  -- CREATE, UPDATE, DELETE, READ, etc.
    ENTITY_TYPE VARCHAR(100) NOT NULL,  -- Table name
    ENTITY_ID VARCHAR(36),
    
    -- Details
    OLD_VALUE NCLOB,  -- JSON snapshot before change
    NEW_VALUE NCLOB,  -- JSON snapshot after change
    CHANGED_FIELDS VARCHAR(1000),  -- Comma-separated list
    
    -- Context
    IP_ADDRESS VARCHAR(50),
    USER_AGENT VARCHAR(500),
    SESSION_ID VARCHAR(36),
    REQUEST_ID VARCHAR(36),
    
    -- Metadata
    TIMESTAMP TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    SUCCESS BOOLEAN DEFAULT TRUE,
    ERROR_MESSAGE VARCHAR(1000)
);

CREATE INDEX IDX_AUDIT_USER ON AUDIT_LOG(USER_ID);
CREATE INDEX IDX_AUDIT_ACTION ON AUDIT_LOG(ACTION);
CREATE INDEX IDX_AUDIT_ENTITY ON AUDIT_LOG(ENTITY_TYPE, ENTITY_ID);
CREATE INDEX IDX_AUDIT_TIMESTAMP ON AUDIT_LOG(TIMESTAMP);
CREATE INDEX IDX_AUDIT_SUCCESS ON AUDIT_LOG(SUCCESS);

COMMENT ON TABLE AUDIT_LOG IS 'Comprehensive audit trail for all database operations';

-- ============================================================================
-- VIEWS FOR COMMON QUERIES
-- ============================================================================

-- View: User's unread notifications count
CREATE VIEW V_USER_UNREAD_NOTIFICATIONS AS
SELECT 
    USER_ID,
    COUNT(*) as UNREAD_COUNT,
    SUM(CASE WHEN TYPE = 'error' THEN 1 ELSE 0 END) as ERROR_COUNT,
    SUM(CASE WHEN TYPE = 'warning' THEN 1 ELSE 0 END) as WARNING_COUNT,
    SUM(CASE WHEN TYPE = 'info' THEN 1 ELSE 0 END) as INFO_COUNT,
    MAX(CREATED_AT) as MOST_RECENT
FROM NOTIFICATIONS
WHERE IS_READ = FALSE 
  AND (EXPIRES_AT IS NULL OR EXPIRES_AT > CURRENT_TIMESTAMP)
GROUP BY USER_ID;

-- View: Model configuration summary
CREATE VIEW V_MODEL_CONFIGS_SUMMARY AS
SELECT 
    MODEL_ID,
    COUNT(DISTINCT USER_ID) as TOTAL_USERS,
    COUNT(*) as TOTAL_CONFIGS,
    AVG(TEMPERATURE) as AVG_TEMPERATURE,
    AVG(TOP_P) as AVG_TOP_P,
    AVG(MAX_TOKENS) as AVG_MAX_TOKENS,
    MAX(UPDATED_AT) as LAST_UPDATED
FROM MODEL_CONFIGURATIONS
GROUP BY MODEL_ID;

-- View: Recent prompt comparisons
CREATE VIEW V_RECENT_PROMPT_COMPARISONS AS
SELECT 
    COMPARISON_ID,
    USER_ID,
    COMPARISON_NAME,
    PROMPT_A_MODE,
    PROMPT_B_MODE,
    OVERALL_WINNER,
    CASE 
        WHEN PROMPT_A_LATENCY_MS < PROMPT_B_LATENCY_MS 
        THEN PROMPT_A_LATENCY_MS 
        ELSE PROMPT_B_LATENCY_MS 
    END as BEST_LATENCY_MS,
    IS_SAVED,
    IS_FAVORITE,
    CREATED_AT
FROM PROMPT_COMPARISONS
WHERE CREATED_AT > ADD_DAYS(CURRENT_TIMESTAMP, -30)
ORDER BY CREATED_AT DESC;

-- View: Training experiment success rates
CREATE VIEW V_TRAINING_SUCCESS_RATES AS
SELECT 
    BASE_MODEL,
    FINE_TUNING_METHOD,
    COUNT(*) as TOTAL_EXPERIMENTS,
    SUM(CASE WHEN STATUS = 'COMPLETED' THEN 1 ELSE 0 END) as COMPLETED,
    SUM(CASE WHEN STATUS = 'FAILED' THEN 1 ELSE 0 END) as FAILED,
    AVG(CASE WHEN STATUS = 'COMPLETED' THEN FINAL_ACCURACY ELSE NULL END) as AVG_FINAL_ACCURACY,
    AVG(CASE WHEN STATUS = 'COMPLETED' THEN DURATION_SECONDS ELSE NULL END) as AVG_DURATION_SEC
FROM TRAINING_EXPERIMENTS
WHERE CREATED_AT > ADD_DAYS(CURRENT_TIMESTAMP, -90)
GROUP BY BASE_MODEL, FINE_TUNING_METHOD;

-- ============================================================================
-- INITIAL SEED DATA
-- ============================================================================

-- Insert default notification types for testing
INSERT INTO NOTIFICATIONS (
    NOTIFICATION_ID, USER_ID, TYPE, CATEGORY, TITLE, MESSAGE,
    ACTION, ACTION_TEXT, PRIORITY, CREATED_AT
) VALUES (
    'notif_welcome_001', 
    'system', 
    'info', 
    'System', 
    'Welcome to Nucleus OpenAI Server',
    'Your dashboard is ready. Start by selecting a model and running your first prompt.',
    'viewDashboard',
    'Go to Dashboard',
    1,
    CURRENT_TIMESTAMP
);

-- ============================================================================
-- STORED PROCEDURES (Helper Functions)
-- ============================================================================

-- Procedure: Calculate prompt comparison winner
CREATE OR REPLACE PROCEDURE SP_CALCULATE_PROMPT_WINNER(
    IN comparison_id VARCHAR(36)
)
LANGUAGE SQLSCRIPT AS
BEGIN
    DECLARE winner_a_count INT;
    DECLARE winner_b_count INT;
    DECLARE overall_winner VARCHAR(1);
    
    -- Count wins for each side
    SELECT 
        SUM(CASE WHEN LATENCY_WINNER = 'A' THEN 1 ELSE 0 END) +
        SUM(CASE WHEN TTFT_WINNER = 'A' THEN 1 ELSE 0 END) +
        SUM(CASE WHEN TPS_WINNER = 'A' THEN 1 ELSE 0 END) +
        SUM(CASE WHEN COST_WINNER = 'A' THEN 1 ELSE 0 END),
        SUM(CASE WHEN LATENCY_WINNER = 'B' THEN 1 ELSE 0 END) +
        SUM(CASE WHEN TTFT_WINNER = 'B' THEN 1 ELSE 0 END) +
        SUM(CASE WHEN TPS_WINNER = 'B' THEN 1 ELSE 0 END) +
        SUM(CASE WHEN COST_WINNER = 'B' THEN 1 ELSE 0 END)
    INTO winner_a_count, winner_b_count
    FROM PROMPT_COMPARISONS
    WHERE COMPARISON_ID = :comparison_id;
    
    -- Determine overall winner
    IF winner_a_count > winner_b_count THEN
        overall_winner := 'A';
    ELSEIF winner_b_count > winner_a_count THEN
        overall_winner := 'B';
    ELSE
        overall_winner := NULL;  -- Tie
    END IF;
    
    -- Update comparison
    UPDATE PROMPT_COMPARISONS
    SET OVERALL_WINNER = :overall_winner,
        UPDATED_AT = CURRENT_TIMESTAMP
    WHERE COMPARISON_ID = :comparison_id;
END;

-- Procedure: Auto-expire old notifications
CREATE OR REPLACE PROCEDURE SP_EXPIRE_OLD_NOTIFICATIONS()
LANGUAGE SQLSCRIPT AS
BEGIN
    UPDATE NOTIFICATIONS
    SET IS_DISMISSED = TRUE,
        DISMISSED_AT = CURRENT_TIMESTAMP
    WHERE EXPIRES_AT IS NOT NULL 
      AND EXPIRES_AT < CURRENT_TIMESTAMP
      AND IS_DISMISSED = FALSE;
END;

-- Procedure: Cleanup old audit logs (keep last 90 days)
CREATE OR REPLACE PROCEDURE SP_CLEANUP_AUDIT_LOGS()
LANGUAGE SQLSCRIPT AS
BEGIN
    DELETE FROM AUDIT_LOG
    WHERE TIMESTAMP < ADD_DAYS(CURRENT_TIMESTAMP, -90);
END;

-- ============================================================================
-- TRIGGERS (Automated Actions)
-- ============================================================================

-- Trigger: Update UPDATED_AT timestamp on configuration changes
CREATE OR REPLACE TRIGGER TRG_MODEL_CONFIG_UPDATE
    BEFORE UPDATE ON MODEL_CONFIGURATIONS
    FOR EACH ROW
BEGIN
    :NEW.UPDATED_AT := CURRENT_TIMESTAMP;
END;

-- Trigger: Log configuration changes to audit log
CREATE OR REPLACE TRIGGER TRG_MODEL_CONFIG_AUDIT
    AFTER INSERT OR UPDATE OR DELETE ON MODEL_CONFIGURATIONS
    FOR EACH ROW
BEGIN
    IF :operation = 'INSERT' THEN
        INSERT INTO AUDIT_LOG (
            AUDIT_ID, USER_ID, ACTION, ENTITY_TYPE, ENTITY_ID, NEW_VALUE, TIMESTAMP
        ) VALUES (
            SYSUUID, :NEW.USER_ID, 'CREATE', 'MODEL_CONFIGURATIONS', :NEW.CONFIG_ID,
            TO_NCLOB(:NEW), CURRENT_TIMESTAMP
        );
    ELSEIF :operation = 'UPDATE' THEN
        INSERT INTO AUDIT_LOG (
            AUDIT_ID, USER_ID, ACTION, ENTITY_TYPE, ENTITY_ID, OLD_VALUE, NEW_VALUE, TIMESTAMP
        ) VALUES (
            SYSUUID, :NEW.USER_ID, 'UPDATE', 'MODEL_CONFIGURATIONS', :NEW.CONFIG_ID,
            TO_NCLOB(:OLD), TO_NCLOB(:NEW), CURRENT_TIMESTAMP
        );
    ELSEIF :operation = 'DELETE' THEN
        INSERT INTO AUDIT_LOG (
            AUDIT_ID, USER_ID, ACTION, ENTITY_TYPE, ENTITY_ID, OLD_VALUE, TIMESTAMP
        ) VALUES (
            SYSUUID, :OLD.USER_ID, 'DELETE', 'MODEL_CONFIGURATIONS', :OLD.CONFIG_ID,
            TO_NCLOB(:OLD), CURRENT_TIMESTAMP
        );
    END IF;
END;

-- ============================================================================
-- GRANT PERMISSIONS
-- ============================================================================

-- Grant to application user (adjust as needed)
GRANT SELECT, INSERT, UPDATE, DELETE ON MODEL_CONFIGURATIONS TO NUCLEUS_APP;
GRANT SELECT, INSERT, UPDATE, DELETE ON USER_SETTINGS TO NUCLEUS_APP;
GRANT SELECT, INSERT, UPDATE, DELETE ON NOTIFICATIONS TO NUCLEUS_APP;
GRANT SELECT, INSERT, UPDATE, DELETE ON PROMPT_COMPARISONS TO NUCLEUS_APP;
GRANT SELECT, INSERT, UPDATE, DELETE ON MODEL_VERSIONS TO NUCLEUS_APP;
GRANT SELECT, INSERT, UPDATE, DELETE ON MODEL_VERSION_COMPARISONS TO NUCLEUS_APP;
GRANT SELECT, INSERT, UPDATE, DELETE ON TRAINING_EXPERIMENTS TO NUCLEUS_APP;
GRANT SELECT, INSERT, UPDATE, DELETE ON TRAINING_EXPERIMENT_COMPARISONS TO NUCLEUS_APP;
GRANT SELECT, INSERT ON AUDIT_LOG TO NUCLEUS_APP;

-- Grant view access
GRANT SELECT ON V_USER_UNREAD_NOTIFICATIONS TO NUCLEUS_APP;
GRANT SELECT ON V_MODEL_CONFIGS_SUMMARY TO NUCLEUS_APP;
GRANT SELECT ON V_RECENT_PROMPT_COMPARISONS TO NUCLEUS_APP;
GRANT SELECT ON V_TRAINING_SUCCESS_RATES TO NUCLEUS_APP;

-- Grant procedure execution
GRANT EXECUTE ON SP_CALCULATE_PROMPT_WINNER TO NUCLEUS_APP;
GRANT EXECUTE ON SP_EXPIRE_OLD_NOTIFICATIONS TO NUCLEUS_APP;
GRANT EXECUTE ON SP_CLEANUP_AUDIT_LOGS TO NUCLEUS_APP;

-- ============================================================================
-- VERIFICATION QUERIES
-- ============================================================================

-- Verify all tables created
SELECT TABLE_NAME, RECORD_COUNT 
FROM M_TABLES 
WHERE SCHEMA_NAME = 'NUCLEUS'
ORDER BY TABLE_NAME;

-- Verify all indexes created
SELECT TABLE_NAME, INDEX_NAME, INDEX_TYPE
FROM M_INDEXES
WHERE SCHEMA_NAME = 'NUCLEUS'
ORDER BY TABLE_NAME, INDEX_NAME;

-- Verify all views created
SELECT VIEW_NAME, CREATE_TIME
FROM VIEWS
WHERE SCHEMA_NAME = 'NUCLEUS'
ORDER BY VIEW_NAME;

-- Verify procedures created
SELECT PROCEDURE_NAME, CREATE_TIME
FROM PROCEDURES
WHERE SCHEMA_NAME = 'NUCLEUS'
ORDER BY PROCEDURE_NAME;

COMMIT;

-- ============================================================================
-- DAY 21: MODEL ROUTER DATA MODEL (Week 5, Monday)
-- ============================================================================

DROP TABLE IF EXISTS AGENT_MODEL_ASSIGNMENTS;
DROP TABLE IF EXISTS ROUTING_DECISIONS;

-- Agent Model Assignments Table
CREATE COLUMN TABLE AGENT_MODEL_ASSIGNMENTS (
    ASSIGNMENT_ID VARCHAR(36) PRIMARY KEY,
    
    -- Agent Information
    AGENT_ID VARCHAR(100) NOT NULL,
    AGENT_NAME VARCHAR(200),
    AGENT_TYPE VARCHAR(50),  -- 'inference', 'tool', 'orchestrator'
    AGENT_CAPABILITIES_JSON NCLOB,  -- JSON array of capabilities
    
    -- Model Assignment
    MODEL_ID VARCHAR(100) NOT NULL,
    MODEL_NAME VARCHAR(200),
    MODEL_CAPABILITIES_JSON NCLOB,  -- JSON array of model capabilities
    
    -- Capability Matching
    MATCH_SCORE DECIMAL(5,2) NOT NULL CHECK (MATCH_SCORE >= 0.0 AND MATCH_SCORE <= 100.0),
    CAPABILITY_OVERLAP_JSON NCLOB,  -- JSON array of matching capabilities
    
    -- Assignment Status
    STATUS VARCHAR(20) DEFAULT 'ACTIVE' 
        CHECK (STATUS IN ('ACTIVE', 'INACTIVE', 'TESTING', 'OVERRIDDEN')),
    
    -- Assignment Strategy
    ASSIGNMENT_METHOD VARCHAR(20) DEFAULT 'AUTO' 
        CHECK (ASSIGNMENT_METHOD IN ('AUTO', 'MANUAL', 'FALLBACK')),
    
    -- Performance Weights (for routing decisions)
    PERFORMANCE_WEIGHT DECIMAL(3,2) DEFAULT 1.0 
        CHECK (PERFORMANCE_WEIGHT >= 0.0 AND PERFORMANCE_WEIGHT <= 1.0),
    CAPABILITY_WEIGHT DECIMAL(3,2) DEFAULT 1.0 
        CHECK (CAPABILITY_WEIGHT >= 0.0 AND CAPABILITY_WEIGHT <= 1.0),
    
    -- Assignment Metadata
    ASSIGNED_BY VARCHAR(100),
    ASSIGNED_AT TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    LAST_UPDATED TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    NOTES VARCHAR(1000),
    
    -- Performance Tracking
    TOTAL_REQUESTS INTEGER DEFAULT 0,
    SUCCESSFUL_REQUESTS INTEGER DEFAULT 0,
    FAILED_REQUESTS INTEGER DEFAULT 0,
    AVG_LATENCY_MS INTEGER,
    LAST_USED_AT TIMESTAMP,
    
    CONSTRAINT UQ_AGENT_MODEL UNIQUE (AGENT_ID, MODEL_ID)
);

CREATE INDEX IDX_AMA_AGENT ON AGENT_MODEL_ASSIGNMENTS(AGENT_ID);
CREATE INDEX IDX_AMA_MODEL ON AGENT_MODEL_ASSIGNMENTS(MODEL_ID);
CREATE INDEX IDX_AMA_STATUS ON AGENT_MODEL_ASSIGNMENTS(STATUS);
CREATE INDEX IDX_AMA_SCORE ON AGENT_MODEL_ASSIGNMENTS(MATCH_SCORE);
CREATE INDEX IDX_AMA_METHOD ON AGENT_MODEL_ASSIGNMENTS(ASSIGNMENT_METHOD);
CREATE INDEX IDX_AMA_ASSIGNED ON AGENT_MODEL_ASSIGNMENTS(ASSIGNED_AT);

COMMENT ON TABLE AGENT_MODEL_ASSIGNMENTS IS 'Day 21: Agent-to-model assignment mappings with capability scoring';

-- Routing Decisions Table
CREATE COLUMN TABLE ROUTING_DECISIONS (
    DECISION_ID VARCHAR(36) PRIMARY KEY,
    
    -- Request Context
    REQUEST_ID VARCHAR(36),
    TIMESTAMP TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    -- Task Information
    TASK_TYPE VARCHAR(50) NOT NULL,  -- 'coding', 'math', 'reasoning', 'arabic', 'general'
    TASK_DESCRIPTION VARCHAR(1000),
    CONTEXT_LENGTH INTEGER,
    PROMPT_PREVIEW VARCHAR(500),
    
    -- Routing Decision
    SELECTED_AGENT_ID VARCHAR(100) NOT NULL,
    SELECTED_MODEL_ID VARCHAR(100) NOT NULL,
    ASSIGNMENT_ID VARCHAR(36),  -- Reference to AGENT_MODEL_ASSIGNMENTS
    
    -- Scoring Details
    CAPABILITY_SCORE DECIMAL(5,2) CHECK (CAPABILITY_SCORE >= 0.0 AND CAPABILITY_SCORE <= 100.0),
    PERFORMANCE_SCORE DECIMAL(5,2) CHECK (PERFORMANCE_SCORE >= 0.0 AND PERFORMANCE_SCORE <= 100.0),
    COMPOSITE_SCORE DECIMAL(5,2) CHECK (COMPOSITE_SCORE >= 0.0 AND COMPOSITE_SCORE <= 100.0),
    
    -- Routing Strategy Used
    STRATEGY VARCHAR(20) DEFAULT 'balanced' 
        CHECK (STRATEGY IN ('balanced', 'speed', 'quality', 'cost')),
    
    -- Alternative Candidates (JSON)
    RUNNER_UPS_JSON NCLOB,  -- JSON array of alternate agent-model pairs with scores
    
    -- Execution Results
    SUCCESS BOOLEAN,
    LATENCY_MS INTEGER,
    TOKENS_GENERATED INTEGER,
    ERROR_MESSAGE VARCHAR(1000),
    
    -- Feedback Loop
    USER_RATING INTEGER CHECK (USER_RATING BETWEEN 1 AND 5),
    USER_FEEDBACK VARCHAR(1000),
    
    -- Cost Tracking
    ESTIMATED_COST DECIMAL(10,6),
    ACTUAL_COST DECIMAL(10,6),
    
    -- Fallback Information
    IS_FALLBACK BOOLEAN DEFAULT FALSE,
    FALLBACK_REASON VARCHAR(500),
    PRIMARY_FAILURE_REASON VARCHAR(500),
    
    CONSTRAINT FK_ASSIGNMENT FOREIGN KEY (ASSIGNMENT_ID) 
        REFERENCES AGENT_MODEL_ASSIGNMENTS(ASSIGNMENT_ID) ON DELETE SET NULL
);

CREATE INDEX IDX_RD_AGENT ON ROUTING_DECISIONS(SELECTED_AGENT_ID);
CREATE INDEX IDX_RD_MODEL ON ROUTING_DECISIONS(SELECTED_MODEL_ID);
CREATE INDEX IDX_RD_TASK_TYPE ON ROUTING_DECISIONS(TASK_TYPE);
CREATE INDEX IDX_RD_TIMESTAMP ON ROUTING_DECISIONS(TIMESTAMP);
CREATE INDEX IDX_RD_SUCCESS ON ROUTING_DECISIONS(SUCCESS);
CREATE INDEX IDX_RD_STRATEGY ON ROUTING_DECISIONS(STRATEGY);
CREATE INDEX IDX_RD_FALLBACK ON ROUTING_DECISIONS(IS_FALLBACK);
CREATE INDEX IDX_RD_ASSIGNMENT ON ROUTING_DECISIONS(ASSIGNMENT_ID);
CREATE INDEX IDX_RD_REQUEST ON ROUTING_DECISIONS(REQUEST_ID);

COMMENT ON TABLE ROUTING_DECISIONS IS 'Day 21: Routing decision history with task types and performance tracking';

-- ============================================================================
-- DAY 21: VIEWS FOR ROUTING ANALYTICS
-- ============================================================================

-- View: Current Agent Assignments Summary
CREATE VIEW V_AGENT_ASSIGNMENTS_SUMMARY AS
SELECT 
    AGENT_ID,
    AGENT_NAME,
    AGENT_TYPE,
    COUNT(*) as TOTAL_MODELS_ASSIGNED,
    COUNT(CASE WHEN STATUS = 'ACTIVE' THEN 1 END) as ACTIVE_ASSIGNMENTS,
    AVG(MATCH_SCORE) as AVG_MATCH_SCORE,
    SUM(TOTAL_REQUESTS) as TOTAL_REQUESTS,
    SUM(SUCCESSFUL_REQUESTS) as SUCCESSFUL_REQUESTS,
    CASE 
        WHEN SUM(TOTAL_REQUESTS) > 0 
        THEN (SUM(SUCCESSFUL_REQUESTS) * 100.0 / SUM(TOTAL_REQUESTS))
        ELSE 0 
    END as SUCCESS_RATE_PERCENT,
    AVG(AVG_LATENCY_MS) as AVG_LATENCY_MS,
    MAX(LAST_USED_AT) as LAST_USED_AT
FROM AGENT_MODEL_ASSIGNMENTS
GROUP BY AGENT_ID, AGENT_NAME, AGENT_TYPE;

-- View: Model Assignment Performance
CREATE VIEW V_MODEL_ASSIGNMENT_PERFORMANCE AS
SELECT 
    MODEL_ID,
    MODEL_NAME,
    COUNT(DISTINCT AGENT_ID) as ASSIGNED_TO_AGENTS,
    COUNT(*) as TOTAL_ASSIGNMENTS,
    AVG(MATCH_SCORE) as AVG_MATCH_SCORE,
    SUM(TOTAL_REQUESTS) as TOTAL_REQUESTS,
    SUM(SUCCESSFUL_REQUESTS) as SUCCESSFUL_REQUESTS,
    CASE 
        WHEN SUM(TOTAL_REQUESTS) > 0 
        THEN (SUM(SUCCESSFUL_REQUESTS) * 100.0 / SUM(TOTAL_REQUESTS))
        ELSE 0 
    END as SUCCESS_RATE_PERCENT,
    AVG(AVG_LATENCY_MS) as AVG_LATENCY_MS
FROM AGENT_MODEL_ASSIGNMENTS
WHERE STATUS = 'ACTIVE'
GROUP BY MODEL_ID, MODEL_NAME;

-- View: Routing Decision Analytics (Last 24 Hours)
CREATE VIEW V_ROUTING_ANALYTICS_24H AS
SELECT 
    TASK_TYPE,
    STRATEGY,
    COUNT(*) as TOTAL_DECISIONS,
    COUNT(CASE WHEN SUCCESS = TRUE THEN 1 END) as SUCCESSFUL_DECISIONS,
    COUNT(CASE WHEN IS_FALLBACK = TRUE THEN 1 END) as FALLBACK_COUNT,
    CASE 
        WHEN COUNT(*) > 0 
        THEN (COUNT(CASE WHEN SUCCESS = TRUE THEN 1 END) * 100.0 / COUNT(*))
        ELSE 0 
    END as SUCCESS_RATE_PERCENT,
    CASE 
        WHEN COUNT(*) > 0 
        THEN (COUNT(CASE WHEN IS_FALLBACK = TRUE THEN 1 END) * 100.0 / COUNT(*))
        ELSE 0 
    END as FALLBACK_RATE_PERCENT,
    AVG(LATENCY_MS) as AVG_LATENCY_MS,
    AVG(COMPOSITE_SCORE) as AVG_COMPOSITE_SCORE,
    AVG(ACTUAL_COST) as AVG_COST
FROM ROUTING_DECISIONS
WHERE TIMESTAMP > ADD_HOURS(CURRENT_TIMESTAMP, -24)
GROUP BY TASK_TYPE, STRATEGY;

-- View: Top Performing Agent-Model Pairs
CREATE VIEW V_TOP_AGENT_MODEL_PAIRS AS
SELECT 
    a.AGENT_ID,
    a.AGENT_NAME,
    a.MODEL_ID,
    a.MODEL_NAME,
    a.MATCH_SCORE,
    a.TOTAL_REQUESTS,
    a.SUCCESSFUL_REQUESTS,
    CASE 
        WHEN a.TOTAL_REQUESTS > 0 
        THEN (a.SUCCESSFUL_REQUESTS * 100.0 / a.TOTAL_REQUESTS)
        ELSE 0 
    END as SUCCESS_RATE_PERCENT,
    a.AVG_LATENCY_MS,
    a.STATUS,
    COUNT(r.DECISION_ID) as RECENT_USES_24H
FROM AGENT_MODEL_ASSIGNMENTS a
LEFT JOIN ROUTING_DECISIONS r 
    ON a.AGENT_ID = r.SELECTED_AGENT_ID 
    AND a.MODEL_ID = r.SELECTED_MODEL_ID
    AND r.TIMESTAMP > ADD_HOURS(CURRENT_TIMESTAMP, -24)
WHERE a.STATUS = 'ACTIVE'
GROUP BY 
    a.AGENT_ID, a.AGENT_NAME, a.MODEL_ID, a.MODEL_NAME,
    a.MATCH_SCORE, a.TOTAL_REQUESTS, a.SUCCESSFUL_REQUESTS, 
    a.AVG_LATENCY_MS, a.STATUS
ORDER BY SUCCESS_RATE_PERCENT DESC, AVG_LATENCY_MS ASC;

-- ============================================================================
-- DAY 21: STORED PROCEDURES FOR ROUTING
-- ============================================================================

-- Procedure: Auto-assign models to agents based on capabilities
CREATE OR REPLACE PROCEDURE SP_AUTO_ASSIGN_MODELS()
LANGUAGE SQLSCRIPT AS
BEGIN
    -- This is a placeholder for the auto-assignment algorithm
    -- Will be implemented in capability_scorer.zig and auto_assign.zig
    -- The procedure will be called from the Zig backend after scoring
    
    -- For now, just log the call
    INSERT INTO AUDIT_LOG (
        AUDIT_ID, USER_ID, ACTION, ENTITY_TYPE, TIMESTAMP
    ) VALUES (
        SYSUUID, 'system', 'AUTO_ASSIGN', 'AGENT_MODEL_ASSIGNMENTS', CURRENT_TIMESTAMP
    );
END;

-- Procedure: Update assignment performance metrics
CREATE OR REPLACE PROCEDURE SP_UPDATE_ASSIGNMENT_METRICS(
    IN p_assignment_id VARCHAR(36),
    IN p_success BOOLEAN,
    IN p_latency_ms INTEGER
)
LANGUAGE SQLSCRIPT AS
BEGIN
    DECLARE current_total INTEGER;
    DECLARE current_successful INTEGER;
    DECLARE current_avg_latency INTEGER;
    DECLARE new_avg_latency INTEGER;
    
    -- Get current metrics
    SELECT TOTAL_REQUESTS, SUCCESSFUL_REQUESTS, AVG_LATENCY_MS
    INTO current_total, current_successful, current_avg_latency
    FROM AGENT_MODEL_ASSIGNMENTS
    WHERE ASSIGNMENT_ID = :p_assignment_id;
    
    -- Calculate new metrics
    IF p_success = TRUE THEN
        current_successful := current_successful + 1;
    END IF;
    
    current_total := current_total + 1;
    
    -- Calculate rolling average latency
    IF current_avg_latency IS NULL THEN
        new_avg_latency := p_latency_ms;
    ELSE
        new_avg_latency := ((current_avg_latency * (current_total - 1)) + p_latency_ms) / current_total;
    END IF;
    
    -- Update assignment
    UPDATE AGENT_MODEL_ASSIGNMENTS
    SET TOTAL_REQUESTS = current_total,
        SUCCESSFUL_REQUESTS = current_successful,
        AVG_LATENCY_MS = new_avg_latency,
        LAST_USED_AT = CURRENT_TIMESTAMP,
        LAST_UPDATED = CURRENT_TIMESTAMP
    WHERE ASSIGNMENT_ID = :p_assignment_id;
END;

-- Procedure: Get routing recommendation
CREATE OR REPLACE PROCEDURE SP_GET_ROUTING_RECOMMENDATION(
    IN p_task_type VARCHAR(50),
    IN p_strategy VARCHAR(20),
    OUT o_agent_id VARCHAR(100),
    OUT o_model_id VARCHAR(100),
    OUT o_assignment_id VARCHAR(36),
    OUT o_score DECIMAL(5,2)
)
LANGUAGE SQLSCRIPT AS
BEGIN
    -- Select best agent-model pair based on strategy
    IF p_strategy = 'speed' THEN
        -- Prioritize latency
        SELECT AGENT_ID, MODEL_ID, ASSIGNMENT_ID, MATCH_SCORE
        INTO o_agent_id, o_model_id, o_assignment_id, o_score
        FROM AGENT_MODEL_ASSIGNMENTS
        WHERE STATUS = 'ACTIVE'
        ORDER BY AVG_LATENCY_MS ASC, MATCH_SCORE DESC
        LIMIT 1;
    ELSEIF p_strategy = 'quality' THEN
        -- Prioritize match score and success rate
        SELECT AGENT_ID, MODEL_ID, ASSIGNMENT_ID, MATCH_SCORE
        INTO o_agent_id, o_model_id, o_assignment_id, o_score
        FROM AGENT_MODEL_ASSIGNMENTS
        WHERE STATUS = 'ACTIVE'
          AND TOTAL_REQUESTS > 0
        ORDER BY (SUCCESSFUL_REQUESTS * 100.0 / TOTAL_REQUESTS) DESC, MATCH_SCORE DESC
        LIMIT 1;
    ELSE
        -- Balanced strategy (default)
        SELECT AGENT_ID, MODEL_ID, ASSIGNMENT_ID, MATCH_SCORE
        INTO o_agent_id, o_model_id, o_assignment_id, o_score
        FROM AGENT_MODEL_ASSIGNMENTS
        WHERE STATUS = 'ACTIVE'
        ORDER BY (MATCH_SCORE * 0.6 + 
                 CASE WHEN TOTAL_REQUESTS > 0 
                      THEN (SUCCESSFUL_REQUESTS * 100.0 / TOTAL_REQUESTS) * 0.4 
                      ELSE 0 END) DESC
        LIMIT 1;
    END IF;
END;

-- ============================================================================
-- DAY 21: GRANT PERMISSIONS
-- ============================================================================

GRANT SELECT, INSERT, UPDATE, DELETE ON AGENT_MODEL_ASSIGNMENTS TO NUCLEUS_APP;
GRANT SELECT, INSERT, UPDATE ON ROUTING_DECISIONS TO NUCLEUS_APP;
GRANT SELECT ON V_AGENT_ASSIGNMENTS_SUMMARY TO NUCLEUS_APP;
GRANT SELECT ON V_MODEL_ASSIGNMENT_PERFORMANCE TO NUCLEUS_APP;
GRANT SELECT ON V_ROUTING_ANALYTICS_24H TO NUCLEUS_APP;
GRANT SELECT ON V_TOP_AGENT_MODEL_PAIRS TO NUCLEUS_APP;
GRANT EXECUTE ON SP_AUTO_ASSIGN_MODELS TO NUCLEUS_APP;
GRANT EXECUTE ON SP_UPDATE_ASSIGNMENT_METRICS TO NUCLEUS_APP;
GRANT EXECUTE ON SP_GET_ROUTING_RECOMMENDATION TO NUCLEUS_APP;

-- ============================================================================
-- DAY 21: SEED DATA FOR TESTING
-- ============================================================================

-- Insert sample agent-model assignments for testing
INSERT INTO AGENT_MODEL_ASSIGNMENTS (
    ASSIGNMENT_ID, AGENT_ID, AGENT_NAME, AGENT_TYPE, MODEL_ID, MODEL_NAME,
    MATCH_SCORE, STATUS, ASSIGNMENT_METHOD, ASSIGNED_BY
) VALUES 
(
    'ama_001', 'agent_gpu_1', 'GPU Inference Agent 1', 'inference',
    'llama3-70b', 'LLaMA 3 70B', 95.0, 'ACTIVE', 'AUTO', 'system'
),
(
    'ama_002', 'agent_gpu_2', 'GPU Inference Agent 2', 'inference',
    'mistral-7b', 'Mistral 7B', 88.5, 'ACTIVE', 'AUTO', 'system'
),
(
    'ama_003', 'agent_cpu_1', 'CPU Inference Agent 1', 'inference',
    'tinyllama-1b', 'TinyLLaMA 1.1B', 75.0, 'ACTIVE', 'AUTO', 'system'
);

-- ============================================================================
-- SCHEMA SUMMARY (UPDATED)
-- ============================================================================
-- Tables Created: 11 new tables
--   1. MODEL_CONFIGURATIONS (18 columns) - Model inference parameters
--   2. USER_SETTINGS (24 columns) - User application settings
--   3. NOTIFICATIONS (15 columns) - System notifications
--   4. PROMPT_COMPARISONS (30 columns) - Prompt A vs B comparisons
--   5. MODEL_VERSIONS (15 columns) - Model version history
--   6. MODEL_VERSION_COMPARISONS (25 columns) - Version A vs B comparisons
--   7. TRAINING_EXPERIMENTS (25 columns) - Training job metadata
--   8. TRAINING_EXPERIMENT_COMPARISONS (27 columns) - Experiment A vs B comparisons
--   9. AUDIT_LOG (12 columns) - Audit trail for all operations
--   10. AGENT_MODEL_ASSIGNMENTS (21 columns) - Day 21: Agent-model assignments
--   11. ROUTING_DECISIONS (24 columns) - Day 21: Routing decision history
--
-- Indexes Created: 40 indexes
-- Views Created: 8 views
-- Procedures Created: 6 stored procedures
-- Triggers Created: 2 triggers
--
-- Day 21 Complete: Router Data Model implemented
-- ============================================================================
