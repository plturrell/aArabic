/Users/user/Documents/arabic_folder/src/serviceCore/nAudioLab/docs/implementation-plan.md# HiFiGAN Training Configuration - Day 27
# AudioLabShimmy Neural Vocoder Training
# Converts mel-spectrograms to 48kHz audio waveforms

# ============================================
# Model Architecture
# ============================================
model:
  # Generator (mel → audio)
  n_mels: 128                    # Input mel bins
  upsample_rates: [8, 8, 2, 2]   # Total upsampling: 256x (128 mel → 48kHz)
  upsample_kernel_sizes: [16, 16, 4, 4]
  resblock_kernel_sizes: [3, 7, 11]  # Multi-receptive field
  resblock_dilation_sizes:
    - [1, 3, 5]
    - [1, 3, 5]
    - [1, 3, 5]
  upsample_initial_channel: 512  # Initial feature channels
  
  # Discriminators
  mpd_periods: [2, 3, 5, 7, 11]  # Multi-period discriminator
  msd_scales: 3                   # Multi-scale discriminator

# ============================================
# Training Configuration
# ============================================
training:
  # Steps and duration
  max_steps: 500000              # ~6 days on M3 Max
  batch_size: 16                 # Per-device batch size
  gradient_accumulation: 1       # Effective batch: 16
  
  # Optimization - Generator
  learning_rate_g: 0.0002        # 2e-4
  adam_beta1_g: 0.8
  adam_beta2_g: 0.99
  weight_decay_g: 0.0
  
  # Optimization - Discriminator
  learning_rate_d: 0.0002        # 2e-4
  adam_beta1_d: 0.8
  adam_beta2_d: 0.99
  weight_decay_d: 0.0
  
  # Learning rate schedule
  lr_decay: 0.999                # Exponential decay per step
  lr_decay_start: 200000         # Start decay after 200k steps
  
  # Loss weights
  lambda_fm: 2.0                 # Feature matching loss weight
  lambda_adv: 1.0                # Adversarial loss weight
  lambda_mel: 45.0               # Mel-spectrogram loss weight
  
  # Gradient clipping
  grad_clip_norm: null           # No clipping (null = disabled)
  
  # Multi-resolution STFT loss
  stft_loss_config:
    fft_sizes: [1024, 2048, 512]
    hop_sizes: [256, 512, 128]
    win_sizes: [1024, 2048, 512]

# ============================================
# CPU Optimization
# ============================================
optimization:
  use_accelerate: true           # Apple Accelerate framework
  num_threads: 16                # CPU cores (M3 Max)
  mixed_precision: true          # FP16/FP32 mixed precision
  num_workers: 7                 # Data loading workers
  persistent_workers: true       # Keep workers alive
  pin_memory: false              # Not needed for CPU

# ============================================
# Logging and Checkpoints
# ============================================
logging:
  log_every: 100                 # Log metrics every N steps
  save_every: 5000               # Save checkpoint every N steps
  validate_every: 1000           # Run validation every N steps
  num_validation_samples: 10     # Number of samples to validate
  num_audio_samples: 5           # Number of audio samples to save
  
  # TensorBoard (optional)
  use_tensorboard: false
  tensorboard_dir: data/models/hifigan/tensorboard

# ============================================
# Data Paths
# ============================================
paths:
  # Input data
  data_dir: data/datasets/ljspeech_processed
  train_manifest: data/datasets/ljspeech_processed/training_manifest.json
  val_manifest: data/datasets/ljspeech_processed/validation_manifest.json
  
  # FastSpeech2 checkpoint (for extracting ground-truth mels)
  fastspeech2_checkpoint: data/models/fastspeech2/checkpoints/checkpoint_200000.mojo
  
  # Output directories
  checkpoint_dir: data/models/hifigan/checkpoints
  log_dir: data/models/hifigan/logs
  sample_dir: data/models/hifigan/samples

# ============================================
# Audio Configuration
# ============================================
audio:
  sample_rate: 48000             # Target sample rate
  n_fft: 2048                    # FFT size
  hop_length: 512                # Hop length for STFT
  win_length: 2048               # Window length
  n_mels: 128                    # Number of mel bins
  fmin: 0                        # Minimum frequency
  fmax: 24000                    # Maximum frequency (Nyquist)
  
  # Audio processing
  max_wav_value: 32768.0         # 16-bit audio normalization
  segment_length: 16384          # Audio segment length for training

# ============================================
# Validation Configuration
# ============================================
validation:
  # Test sentences for synthesis
  test_sentences:
    - "The quick brown fox jumps over the lazy dog."
    - "Hello world, this is a test of the text to speech system."
    - "Speech synthesis is the artificial production of human speech."
    - "High quality audio requires careful attention to detail."
    - "The vocoder converts spectrograms into audio waveforms."

# ============================================
# Training Schedule (Days 27-30)
# ============================================
schedule:
  day_27:
    description: "HiFiGAN training setup and initial 50k steps"
    target_steps: 50000
    expected_duration: "24 hours"
    checkpoints: [10000, 20000, 30000, 40000, 50000]
  
  day_28:
    description: "Continue training 50k-150k"
    target_steps: 150000
    expected_duration: "24 hours"
    checkpoints: [75000, 100000, 125000, 150000]
  
  day_29:
    description: "Continue training 150k-300k"
    target_steps: 300000
    expected_duration: "24 hours"
    checkpoints: [200000, 250000, 300000]
  
  day_30:
    description: "Continue training 300k-500k"
    target_steps: 500000
    expected_duration: "24 hours"
    checkpoints: [350000, 400000, 450000, 500000]

# ============================================
# Expected Performance
# ============================================
performance:
  training_speed: "0.3 steps/sec"     # On M3 Max CPU
  steps_per_day: "~25,000"
  total_training_time: "6 days"
  
  expected_losses:
    initial:
      generator: "15-20"
      discriminator: "2-3"
      stft: "10-15"
    
    after_50k:
      generator: "8-12"
      discriminator: "1.5-2.5"
      stft: "5-8"
    
    after_200k:
      generator: "4-6"
      discriminator: "1.0-1.5"
      stft: "2-4"
    
    final_500k:
      generator: "2-4"
      discriminator: "0.8-1.2"
      stft: "1-2"

# ============================================
# Quality Metrics
# ============================================
quality_metrics:
  target_mcd: "< 5.0"              # Mel-cepstral distortion
  target_pesq: "> 4.0"             # Perceptual quality
  target_stoi: "> 0.95"            # Intelligibility
  sample_rate: 48000               # High-quality audio
  bit_depth: 24                    # Studio quality

# ============================================
# Notes
# ============================================
notes: |
  HiFiGAN Training Notes:
  
  1. Generator vs Discriminator Balance:
     - Discriminators should be slightly ahead of generator
     - If D loss < 0.5, generator is winning (reduce G learning rate)
     - If D loss > 2.0, discriminators winning (reduce D learning rate)
  
  2. Multi-Resolution STFT Loss:
     - Most important loss for audio quality
     - Should decrease steadily throughout training
     - Target < 2.0 for good quality
  
  3. Adversarial Training:
     - Alternate G/D updates every step
     - Feature matching helps stabilize training
     - Listen to samples regularly to assess quality
  
  4. Checkpoints:
     - Save every 5k steps (~4 hours)
     - Best checkpoint typically around 300-400k steps
     - Later checkpoints may overfit
  
  5. Audio Quality:
     - First 100k steps: Basic audio structure
     - 100k-300k steps: Improving naturalness
     - 300k-500k steps: Fine details and polish
