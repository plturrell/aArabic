// Generate GPU Validation Report CLI Tool
// ONLY generates reports from actual test measurements
// NO sample/mock data generation - measurements only

const std = @import("std");
const report_gen = @import("report_generator.zig");

pub fn main() !void {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer _ = gpa.deinit();
    const allocator = gpa.allocator();

    const args = try std.process.argsAlloc(allocator);
    defer std.process.argsFree(allocator, args);

    if (args.len < 2) {
        try printUsage();
        return;
    }

    const input_file = args[1];

    // Parse options
    var format = report_gen.ReportFormat.Markdown;
    var output_path: ?[]const u8 = null;

    for (args[2..]) |arg| {
        if (std.mem.startsWith(u8, arg, "--format=")) {
            const fmt = arg[9..];
            if (std.mem.eql(u8, fmt, "json")) {
                format = .JSON;
            } else if (std.mem.eql(u8, fmt, "csv")) {
                format = .CSV;
            } else if (std.mem.eql(u8, fmt, "md") or std.mem.eql(u8, fmt, "markdown")) {
                format = .Markdown;
            } else {
                std.debug.print("Unknown format: {s}\n", .{fmt});
                return error.InvalidFormat;
            }
        } else if (std.mem.startsWith(u8, arg, "--output=")) {
            output_path = arg[9..];
        }
    }

    // Read measurement results from JSON file
    std.debug.print("Reading test results from: {s}\n", .{input_file});
    
    const file = try std.fs.cwd().openFile(input_file, .{});
    defer file.close();

    const file_contents = try file.readToEndAlloc(allocator, 10 * 1024 * 1024); // 10MB max
    defer allocator.free(file_contents);

    // Parse JSON
    const parsed = try std.json.parseFromSlice(
        report_gen.ReportData,
        allocator,
        file_contents,
        .{ .allocate = .alloc_always },
    );
    defer parsed.deinit();

    // Determine output path
    const default_output = switch (format) {
        .Markdown => "gpu_validation_report.md",
        .JSON => "gpu_validation_report.json",
        .CSV => "gpu_validation_report.csv",
    };
    const final_output = output_path orelse default_output;

    // Generate report
    std.debug.print("Generating {s} report...\n", .{@tagName(format)});
    try report_gen.generateReport(allocator, parsed.value, format, final_output);

    std.debug.print("✓ Report generated: {s}\n", .{final_output});
    
    // Print summary to console
    if (parsed.value.gpu_active) {
        if (parsed.value.average_speedup) |speedup| {
            std.debug.print("\nPerformance Summary:\n", .{});
            std.debug.print("  Average Speedup: {d:.1}×\n", .{speedup});
            if (speedup >= 50) {
                std.debug.print("  Status: ✓ GPU acceleration verified\n\n", .{});
            } else {
                std.debug.print("  Status: ⚠ Low GPU utilization\n\n", .{});
            }
        }
    } else {
        std.debug.print("\nStatus: ⚠ GPU not active - CPU measurements only\n", .{});
        std.debug.print("Report shows baseline comparisons for context.\n\n", .{});
    }
}

fn printUsage() !void {
    const usage =
        \\
        \\GPU Validation Report Generator
        \\
        \\USAGE:
        \\  generate_report <results.json> [OPTIONS]
        \\
        \\ARGUMENTS:
        \\  results.json    Path to test results JSON file (REQUIRED)
        \\                  This file must contain actual measurements from test runs.
        \\                  Generated by: test_gpu_diagnostics, benchmark_gpu_vs_cpu, etc.
        \\
        \\OPTIONS:
        \\  --format=FORMAT    Output format: md (default), json, csv
        \\  --output=PATH      Output file path (default: gpu_validation_report.<ext>)
        \\
        \\EXAMPLES:
        \\  # Generate Markdown report from test results
        \\  generate_report test_results.json
        \\
        \\  # Generate JSON report with custom output
        \\  generate_report test_results.json --format=json --output=my_report.json
        \\
        \\  # Generate CSV for spreadsheet analysis
        \\  generate_report test_results.json --format=csv
        \\
        \\WORKFLOW:
        \\  1. Run tests:          zig build test-gpu-integration
        \\  2. Tests export:       test_results_<timestamp>.json
        \\  3. Generate report:    generate_report test_results_<timestamp>.json
        \\
        \\NOTE: This tool only processes ACTUAL MEASUREMENTS.
        \\      It does not generate sample/mock data.
        \\      Industry baselines are used for comparison context only.
        \\
    ;
    std.debug.print("{s}\n", .{usage});
}
