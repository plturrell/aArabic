// Memory-Mapped GGUF Loader
// Zero-copy model weight access from SSD
//
// Key innovations:
// - mmap entire GGUF file - OS handles paging
// - Lazy loading - only pages accessed are loaded
// - Huge pages support for large models
// - Prefetch hints for sequential access patterns
// - Direct tensor slice access without copying

const std = @import("std");

// ============================================================================
// GGUF Constants (from GGUF spec)
// ============================================================================

pub const GGUF_MAGIC: u32 = 0x46554747; // "GGUF" in little-endian
pub const GGUF_VERSION: u32 = 3;

pub const GGMLType = enum(u32) {
    F32 = 0,
    F16 = 1,
    Q4_0 = 2,
    Q4_1 = 3,
    Q5_0 = 6,
    Q5_1 = 7,
    Q8_0 = 8,
    Q8_1 = 9,
    Q2_K = 10,
    Q3_K = 11,
    Q4_K = 12,
    Q5_K = 13,
    Q6_K = 14,
    Q8_K = 15,
    IQ2_XXS = 16,
    IQ2_XS = 17,
    IQ3_XXS = 18,
    IQ1_S = 19,
    IQ4_NL = 20,
    IQ3_S = 21,
    IQ2_S = 22,
    IQ4_XS = 23,
    I8 = 24,
    I16 = 25,
    I32 = 26,
    I64 = 27,
    F64 = 28,
    BF16 = 29,
    _,
    
    pub fn blockSize(self: GGMLType) u32 {
        return switch (self) {
            .F32, .F16, .BF16 => 1,
            .Q4_0, .Q4_1, .Q5_0, .Q5_1, .Q8_0, .Q8_1 => 32,
            .Q2_K, .Q3_K, .Q4_K, .Q5_K, .Q6_K, .Q8_K => 256,
            else => 32,
        };
    }
    
    pub fn bytesPerBlock(self: GGMLType) u32 {
        return switch (self) {
            .F32 => 4,
            .F16, .BF16 => 2,
            .Q4_0 => 18,  // 32 * 0.5 + 2 (scale)
            .Q4_1 => 20,  // 32 * 0.5 + 4 (scale + min)
            .Q8_0 => 34,  // 32 * 1 + 2 (scale)
            .Q4_K => 144, // 256 elements
            .Q6_K => 210,
            else => 18,
        };
    }
};

// ============================================================================
// Tensor Descriptor
// ============================================================================

pub const TensorDescriptor = struct {
    name: []const u8,
    dtype: GGMLType,
    dims: [4]u64,
    n_dims: u32,
    offset: u64,      // Offset in file
    size: u64,        // Size in bytes
    
    pub fn numElements(self: TensorDescriptor) u64 {
        var n: u64 = 1;
        for (0..self.n_dims) |i| {
            n *= self.dims[i];
        }
        return n;
    }
};

// ============================================================================
// Memory-Mapped GGUF File
// ============================================================================

pub const MmapGGUF = struct {
    allocator: std.mem.Allocator,
    
    // File info
    path: []const u8,
    file: std.fs.File,
    file_size: u64,
    
    // Memory mapping
    mmap_base: [*]align(16384) u8,  // macOS page alignment (16KB on Apple Silicon)
    mmap_len: usize,
    
    // GGUF header info
    version: u32,
    n_tensors: u64,
    n_kv: u64,
    
    // Tensor index
    tensors: std.StringHashMap(TensorDescriptor),
    tensor_data_offset: u64,
    
    // Model metadata
    metadata: std.StringHashMap(MetaValue),
    
    // Statistics
    stats: Stats,
    
    pub const MetaValue = union(enum) {
        uint8: u8,
        int8: i8,
        uint16: u16,
        int16: i16,
        uint32: u32,
        int32: i32,
        uint64: u64,
        int64: i64,
        float32: f32,
        float64: f64,
        bool_val: bool,
        string: []const u8,
        array: []const u8, // Raw bytes for arrays
    };
    
    pub const Stats = struct {
        tensors_accessed: u64 = 0,
        bytes_accessed: u64 = 0,
        page_faults: u64 = 0, // Estimated
    };
    
    pub fn open(allocator: std.mem.Allocator, path: []const u8) !*MmapGGUF {
        std.debug.print("\nðŸ“‚ Opening GGUF file: {s}\n", .{path});
        
        const self = try allocator.create(MmapGGUF);
        errdefer allocator.destroy(self);
        
        // Open file
        const file = try std.fs.cwd().openFile(path, .{ .mode = .read_only });
        errdefer file.close();
        
        const file_size = try file.getEndPos();
        std.debug.print("   File size: {d:.2} GB\n", .{
            @as(f64, @floatFromInt(file_size)) / (1024.0 * 1024.0 * 1024.0),
        });
        
        // Memory map the file
        const mmap_base = std.posix.mmap(
            null,
            file_size,
            std.posix.PROT.READ,
            .{ .TYPE = .PRIVATE },
            file.handle,
            0,
        ) catch return error.MmapFailed;

        // Advise kernel about access pattern (ignore errors)
        // Note: madvise hints are optional and may fail on some systems
        _ = std.posix.madvise(mmap_base.ptr, file_size, std.posix.MADV.SEQUENTIAL) catch {};

        // Store path
        const path_copy = try allocator.dupe(u8, path);

        self.* = MmapGGUF{
            .allocator = allocator,
            .path = path_copy,
            .file = file,
            .file_size = file_size,
            .mmap_base = mmap_base.ptr,
            .mmap_len = file_size,
            .version = 0,
            .n_tensors = 0,
            .n_kv = 0,
            .tensors = std.StringHashMap(TensorDescriptor).init(allocator),
            .tensor_data_offset = 0,
            .metadata = std.StringHashMap(MetaValue).init(allocator),
            .stats = .{},
        };

        // Parse header
        try self.parseHeader();

        std.debug.print("   âœ… GGUF mapped: {d} tensors, {d} metadata entries\n", .{
            self.n_tensors, self.n_kv,
        });

        return self;
    }

    fn parseHeader(self: *MmapGGUF) !void {
        var offset: usize = 0;

        // Magic number
        const magic = std.mem.readInt(u32, self.mmap_base[offset..][0..4], .little);
        if (magic != GGUF_MAGIC) {
            return error.InvalidMagic;
        }
        offset += 4;

        // Version
        self.version = std.mem.readInt(u32, self.mmap_base[offset..][0..4], .little);
        offset += 4;

        // Tensor count
        self.n_tensors = std.mem.readInt(u64, self.mmap_base[offset..][0..8], .little);
        offset += 8;

        // Metadata KV count
        self.n_kv = std.mem.readInt(u64, self.mmap_base[offset..][0..8], .little);
        offset += 8;

        std.debug.print("   GGUF v{d}: {d} tensors, {d} metadata\n", .{
            self.version, self.n_tensors, self.n_kv,
        });

        // Parse metadata (skip for now, just find tensor data offset)
        for (0..self.n_kv) |_| {
            offset = try self.skipMetadataEntry(offset);
        }

        // Parse tensor info
        for (0..self.n_tensors) |_| {
            offset = try self.parseTensorInfo(offset);
        }

        // Align to 32 bytes for tensor data
        self.tensor_data_offset = (offset + 31) & ~@as(usize, 31);
    }

    fn skipMetadataEntry(self: *MmapGGUF, start: usize) !usize {
        var offset = start;

        // Key name length
        const key_len = std.mem.readInt(u64, self.mmap_base[offset..][0..8], .little);
        offset += 8;
        offset += @intCast(key_len); // Skip key

        // Value type
        const val_type = std.mem.readInt(u32, self.mmap_base[offset..][0..4], .little);
        offset += 4;

        // Skip value based on type
        offset = try self.skipValue(offset, val_type);

        return offset;
    }

    fn skipValue(self: *MmapGGUF, start: usize, val_type: u32) !usize {
        var offset = start;

        switch (val_type) {
            0 => offset += 1,  // uint8
            1 => offset += 1,  // int8
            2 => offset += 2,  // uint16
            3 => offset += 2,  // int16
            4 => offset += 4,  // uint32
            5 => offset += 4,  // int32
            6 => offset += 4,  // float32
            7 => offset += 1,  // bool
            8 => { // string
                const len = std.mem.readInt(u64, self.mmap_base[offset..][0..8], .little);
                offset += 8 + @as(usize, @intCast(len));
            },
            9 => { // array
                const arr_type = std.mem.readInt(u32, self.mmap_base[offset..][0..4], .little);
                offset += 4;
                const arr_len = std.mem.readInt(u64, self.mmap_base[offset..][0..8], .little);
                offset += 8;
                for (0..arr_len) |_| {
                    offset = try self.skipValue(offset, arr_type);
                }
            },
            10 => offset += 8, // uint64
            11 => offset += 8, // int64
            12 => offset += 8, // float64
            else => return error.UnknownValueType,
        }

        return offset;
    }

    fn parseTensorInfo(self: *MmapGGUF, start: usize) !usize {
        var offset = start;

        // Name
        const name_len = std.mem.readInt(u64, self.mmap_base[offset..][0..8], .little);
        offset += 8;
        const name = self.mmap_base[offset..offset + @as(usize, @intCast(name_len))];
        offset += @intCast(name_len);

        // Dimensions
        const n_dims = std.mem.readInt(u32, self.mmap_base[offset..][0..4], .little);
        offset += 4;

        var dims: [4]u64 = .{1, 1, 1, 1};
        for (0..n_dims) |i| {
            dims[i] = std.mem.readInt(u64, self.mmap_base[offset..][0..8], .little);
            offset += 8;
        }

        // Type
        const dtype_raw = std.mem.readInt(u32, self.mmap_base[offset..][0..4], .little);
        offset += 4;
        const dtype: GGMLType = @enumFromInt(dtype_raw);

        // Offset (relative to tensor data start)
        const tensor_offset = std.mem.readInt(u64, self.mmap_base[offset..][0..8], .little);
        offset += 8;

        // Calculate size
        var n_elements: u64 = 1;
        for (0..n_dims) |i| {
            n_elements *= dims[i];
        }
        const n_blocks = (n_elements + dtype.blockSize() - 1) / dtype.blockSize();
        const size = n_blocks * dtype.bytesPerBlock();

        // Store tensor descriptor
        const name_copy = try self.allocator.dupe(u8, name);
        try self.tensors.put(name_copy, .{
            .name = name_copy,
            .dtype = dtype,
            .dims = dims,
            .n_dims = n_dims,
            .offset = tensor_offset,
            .size = size,
        });

        return offset;
    }

    /// Get raw tensor data (zero-copy slice into mmap)
    pub fn getTensorData(self: *MmapGGUF, name: []const u8) ![]const u8 {
        const desc = self.tensors.get(name) orelse return error.TensorNotFound;

        const start = self.tensor_data_offset + desc.offset;
        const end = start + desc.size;

        self.stats.tensors_accessed += 1;
        self.stats.bytes_accessed += desc.size;

        return self.mmap_base[start..end];
    }

    /// Get tensor as f32 slice (only for F32 tensors)
    pub fn getTensorF32(self: *MmapGGUF, name: []const u8) ![]const f32 {
        const desc = self.tensors.get(name) orelse return error.TensorNotFound;

        if (desc.dtype != .F32) {
            return error.NotF32Tensor;
        }

        const data = try self.getTensorData(name);
        return @alignCast(std.mem.bytesAsSlice(f32, data));
    }

    /// Prefetch tensor data (hint to OS)
    pub fn prefetch(self: *MmapGGUF, name: []const u8) void {
        const desc = self.tensors.get(name) orelse return;
        const start = self.tensor_data_offset + desc.offset;

        // Advise kernel to prefetch
        std.posix.madvise(
            @alignCast((self.mmap_base + start)[0..desc.size]),
            .WILLNEED,
        ) catch {};
    }

    /// Prefetch all tensors matching prefix
    pub fn prefetchPrefix(self: *MmapGGUF, prefix: []const u8) void {
        var iter = self.tensors.iterator();
        while (iter.next()) |entry| {
            if (std.mem.startsWith(u8, entry.key_ptr.*, prefix)) {
                self.prefetch(entry.key_ptr.*);
            }
        }
    }

    /// Get tensor descriptor
    pub fn getTensorDesc(self: *MmapGGUF, name: []const u8) ?TensorDescriptor {
        return self.tensors.get(name);
    }

    /// List all tensor names
    pub fn listTensors(self: *MmapGGUF, allocator: std.mem.Allocator) ![][]const u8 {
        var names = try allocator.alloc([]const u8, self.tensors.count());
        var i: usize = 0;
        var iter = self.tensors.iterator();
        while (iter.next()) |entry| {
            names[i] = entry.key_ptr.*;
            i += 1;
        }
        return names;
    }

    /// Get integer metadata value
    pub fn getMetaInt(self: *MmapGGUF, key: []const u8) ?i64 {
        const val = self.metadata.get(key) orelse return null;
        return switch (val) {
            .uint8 => |v| @as(i64, v),
            .int8 => |v| @as(i64, v),
            .uint16 => |v| @as(i64, v),
            .int16 => |v| @as(i64, v),
            .uint32 => |v| @as(i64, v),
            .int32 => |v| @as(i64, v),
            .uint64 => |v| @as(i64, @intCast(v)),
            .int64 => |v| v,
            else => null,
        };
    }

    /// Get string metadata value
    pub fn getMetaString(self: *MmapGGUF, key: []const u8) ?[]const u8 {
        const val = self.metadata.get(key) orelse return null;
        return switch (val) {
            .string => |s| s,
            else => null,
        };
    }

    /// Get model architecture from metadata
    pub fn getArchitecture(self: *MmapGGUF) []const u8 {
        return self.getMetaString("general.architecture") orelse "unknown";
    }

    /// Print model info
    pub fn printInfo(self: *MmapGGUF) void {
        std.debug.print("\nðŸ“‹ GGUF Model Info\n", .{});
        std.debug.print("   Path: {s}\n", .{self.path});
        std.debug.print("   Size: {d:.2} GB\n", .{
            @as(f64, @floatFromInt(self.file_size)) / (1024.0 * 1024.0 * 1024.0),
        });
        std.debug.print("   Version: {d}\n", .{self.version});
        std.debug.print("   Tensors: {d}\n", .{self.n_tensors});
        std.debug.print("   Metadata: {d}\n", .{self.n_kv});
        std.debug.print("   Tensors accessed: {d}\n", .{self.stats.tensors_accessed});
        std.debug.print("   Bytes accessed: {d:.2} MB\n", .{
            @as(f64, @floatFromInt(self.stats.bytes_accessed)) / (1024.0 * 1024.0),
        });
    }

    pub fn close(self: *MmapGGUF) void {
        std.posix.munmap(@alignCast(self.mmap_base[0..self.mmap_len]));
        self.file.close();

        // Free tensor names
        var iter = self.tensors.iterator();
        while (iter.next()) |entry| {
            self.allocator.free(entry.key_ptr.*);
        }
        self.tensors.deinit();
        self.metadata.deinit();
        self.allocator.free(self.path);
        self.allocator.destroy(self);
    }
};

