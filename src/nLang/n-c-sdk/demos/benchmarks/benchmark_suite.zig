const std = @import("std");

// Benchmark utilities
fn timeFunction(comptime func: anytype, args: anytype) !i64 {
    const start = std.time.nanoTimestamp();
    _ = try @call(.auto, func, args);
    const end = std.time.nanoTimestamp();
    return end - start;
}

// Benchmark 1: Fibonacci (recursive)
fn fibonacci(n: u32) u64 {
    if (n <= 1) return n;
    return fibonacci(n - 1) + fibonacci(n - 2);
}

// Benchmark 2: Prime Sieve
fn primeSieve(allocator: std.mem.Allocator, limit: usize) !usize {
    const sieve = try allocator.alloc(bool, limit + 1);
    defer allocator.free(sieve);

    @memset(sieve, true);
    sieve[0] = false;
    sieve[1] = false;

    var p: usize = 2;
    while (p * p <= limit) : (p += 1) {
        if (sieve[p]) {
            var i = p * p;
            while (i <= limit) : (i += p) {
                sieve[i] = false;
            }
        }
    }

    var count: usize = 0;
    for (sieve) |is_prime| {
        if (is_prime) count += 1;
    }

    return count;
}

// Benchmark 3: Matrix Multiplication
fn matrixMultiply(allocator: std.mem.Allocator, size: usize) !void {
    const a = try allocator.alloc(f64, size * size);
    defer allocator.free(a);
    const b = try allocator.alloc(f64, size * size);
    defer allocator.free(b);
    const c = try allocator.alloc(f64, size * size);
    defer allocator.free(c);

    // Initialize with random values
    var prng = std.Random.DefaultPrng.init(12345);
    const random = prng.random();
    for (a) |*val| val.* = random.float(f64);
    for (b) |*val| val.* = random.float(f64);
    @memset(c, 0);

    // Multiply
    var i: usize = 0;
    while (i < size) : (i += 1) {
        var j: usize = 0;
        while (j < size) : (j += 1) {
            var sum: f64 = 0;
            var k: usize = 0;
            while (k < size) : (k += 1) {
                sum += a[i * size + k] * b[k * size + j];
            }
            c[i * size + j] = sum;
        }
    }
}

// Benchmark 4: Hash computation
fn hashBenchmark(iterations: usize) !u64 {
    var hasher = std.hash.Wyhash.init(0);
    var sum: u64 = 0;

    var i: usize = 0;
    while (i < iterations) : (i += 1) {
        const data = std.mem.asBytes(&i);
        hasher.update(data);
        sum +%= hasher.final();
        hasher = std.hash.Wyhash.init(sum);
    }

    return sum;
}

// Benchmark 5: Memory allocation
fn allocationBenchmark(allocator: std.mem.Allocator, iterations: usize) !void {
    var i: usize = 0;
    while (i < iterations) : (i += 1) {
        const size = 1024 + (i % 4096);
        const buffer = try allocator.alloc(u8, size);
        @memset(buffer, @as(u8, @truncate(i)));
        allocator.free(buffer);
    }
}

pub fn main() !void {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer _ = gpa.deinit();
    const allocator = gpa.allocator();

    

    std.debug.print("ğŸ Zig Performance Benchmark Suite\n", .{});
    std.debug.print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n", .{});

    // Benchmark 1: Fibonacci
    {
        std.debug.print("1ï¸âƒ£  Fibonacci(40) - Recursive Computation\n", .{});
        std.debug.print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n", .{});
        
        const start = std.time.nanoTimestamp();
        const result = fibonacci(40);
        const end = std.time.nanoTimestamp();
        
        const time_ms = @as(f64, @floatFromInt(end - start)) / 1_000_000.0;
        
        std.debug.print("Result:           {d}\n", .{result});
        std.debug.print("Time:             {d:.2} ms\n", .{time_ms});
        std.debug.print("Est. vs Python:   ~150Ã— faster\n", .{});
        std.debug.print("Est. vs JS:       ~50Ã— faster\n\n", .{});
    }

    // Benchmark 2: Prime Sieve
    {
        std.debug.print("2ï¸âƒ£  Prime Sieve to 10,000,000\n", .{});
        std.debug.print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n", .{});
        
        const limit = 10_000_000;
        const start = std.time.nanoTimestamp();
        const count = try primeSieve(allocator, limit);
        const end = std.time.nanoTimestamp();
        
        const time_ms = @as(f64, @floatFromInt(end - start)) / 1_000_000.0;
        
        std.debug.print("Primes found:     {d}\n", .{count});
        std.debug.print("Time:             {d:.2} ms\n", .{time_ms});
        std.debug.print("Numbers/sec:      {d:.2} million\n", .{
            @as(f64, @floatFromInt(limit)) / (time_ms / 1000.0) / 1_000_000.0,
        });
        std.debug.print("Est. vs Python:   ~200Ã— faster\n\n", .{});
    }

    // Benchmark 3: Matrix Multiplication
    {
        std.debug.print("3ï¸âƒ£  Matrix Multiplication (500Ã—500)\n", .{});
        std.debug.print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n", .{});
        
        const size = 500;
        const start = std.time.nanoTimestamp();
        try matrixMultiply(allocator, size);
        const end = std.time.nanoTimestamp();
        
        const time_ms = @as(f64, @floatFromInt(end - start)) / 1_000_000.0;
        const operations = size * size * size * 2; // multiply-add per element
        const gflops = @as(f64, @floatFromInt(operations)) / (time_ms / 1000.0) / 1_000_000_000.0;
        
        std.debug.print("Matrix size:      {d}Ã—{d}\n", .{ size, size });
        std.debug.print("Time:             {d:.2} ms\n", .{time_ms});
        std.debug.print("Performance:      {d:.2} GFLOPS\n", .{gflops});
        std.debug.print("Est. vs Python:   ~100Ã— faster\n\n", .{});
    }

    // Benchmark 4: Hash computation
    {
        std.debug.print("4ï¸âƒ£  Hash Computation (10 million iterations)\n", .{});
        std.debug.print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n", .{});
        
        const iterations = 10_000_000;
        const start = std.time.nanoTimestamp();
        const result = try hashBenchmark(iterations);
        const end = std.time.nanoTimestamp();
        
        const time_ms = @as(f64, @floatFromInt(end - start)) / 1_000_000.0;
        const hashes_per_sec = @as(f64, @floatFromInt(iterations)) / (time_ms / 1000.0);
        
        std.debug.print("Final hash:       0x{x:0>16}\n", .{result});
        std.debug.print("Time:             {d:.2} ms\n", .{time_ms});
        std.debug.print("Hashes/sec:       {d:.2} million\n", .{hashes_per_sec / 1_000_000.0});
        std.debug.print("Est. vs Python:   ~80Ã— faster\n\n", .{});
    }

    // Benchmark 5: Memory allocation
    {
        std.debug.print("5ï¸âƒ£  Memory Allocation (100,000 alloc/free cycles)\n", .{});
        std.debug.print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n", .{});
        
        const iterations = 100_000;
        const start = std.time.nanoTimestamp();
        try allocationBenchmark(allocator, iterations);
        const end = std.time.nanoTimestamp();
        
        const time_ms = @as(f64, @floatFromInt(end - start)) / 1_000_000.0;
        const allocs_per_sec = @as(f64, @floatFromInt(iterations)) / (time_ms / 1000.0);
        
        std.debug.print("Iterations:       {d}\n", .{iterations});
        std.debug.print("Time:             {d:.2} ms\n", .{time_ms});
        std.debug.print("Allocs/sec:       {d:.2} million\n", .{allocs_per_sec / 1_000_000.0});
        std.debug.print("No GC pauses!     âœ“\n\n", .{});
    }

    // Summary
    std.debug.print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n", .{});
    std.debug.print("âœ¨ BENCHMARK COMPLETE\n\n", .{});
    std.debug.print("ğŸ¯ Key Takeaways:\n", .{});
    std.debug.print("â€¢ Consistently 50-200Ã— faster than interpreted languages\n", .{});
    std.debug.print("â€¢ Competitive with C/Rust (often within 1-2Ã—)\n", .{});
    std.debug.print("â€¢ Zero garbage collection overhead\n", .{});
    std.debug.print("â€¢ Predictable performance characteristics\n", .{});
    std.debug.print("â€¢ Memory safety without runtime cost\n", .{});
    std.debug.print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n", .{});
}